{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU03 - Learning Notebook - Part 3 of 3 - Web scraping\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In the context of data wrangling, we've already talked about three data sources: files, databases and public APIs.\n",
    "Now it's time to delve into the Web!\n",
    "\n",
    "As we all know, there is a huge amount of data in the Web. Whenever we search something on Google, it shows us thousands of web pages full of answers.\n",
    "\n",
    "However, there is a problem here: in most of the cases, the web pages show us the data in a beautiful but unstructured way. This makes sense, since the purpose of a web page is to be read by a human and not to have its content analysed by some computer program.\n",
    "\n",
    "So we are left with the boring task of copying and pasting the data we want into csv files or excel tables, possibly thousands of times, before feeding it to some data model...\n",
    "\n",
    "But worry no more!\n",
    "\n",
    "<img src=\"media/web_scraping_to_the_rescue.png\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is web scraping\n",
    "\n",
    "[Web scraping](https://en.wikipedia.org/wiki/Web_scraping) is the name given to the process of extracting data from web pages in an automated way.\n",
    "There are many [techniques](https://en.wikipedia.org/wiki/Web_scraping#Techniques) that can be used to do web scraping and the one we're going to explore here is HTML parsing.\n",
    "\n",
    "A web page is an HTML document, so HTML parsing means to split the contents of a web page into several small pieces and select the parts we find interesting. This technique is useful when we want to extract data from many web pages that share a common template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the HTML code of a web page\n",
    "\n",
    "Before jumping to the part where we actually do web scraping, let's first understand the structure and code of a web page.\n",
    "\n",
    "Usually, a web page has 3 different types of code:\n",
    "* **HTML**: used to display the content of the web page\n",
    "* **CSS**: used to apply styles to the web page, it's what makes the page pretty\n",
    "* **JavaScript**: this is what makes the page dynamic, like triggering an action when a button is clicked.\n",
    "\n",
    "We'll focus now on the HTML part, since it's the one that is related what we want, which is data.\n",
    "\n",
    "In the file **../web_pages/nationalmuseum.html** you can see an example of an HTML document that represents a web page. Let's see the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\r\n",
      "<html>\r\n",
      "  <body>\r\n",
      "    <h1>Webpage about the Nationalmuseum</h1>\r\n",
      "    <h3>It's in Sweden.</h3>\r\n",
      "    <p>For more informations:</p>\r\n",
      "    <br>\r\n",
      "    <p>Check wikipedia!</p>\r\n",
      "  </body>\r\n",
      "</html>"
     ]
    }
   ],
   "source": [
    "# use ! type for Windows (use full path)\n",
    "! cat web_pages/nationalmuseum.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how the page looks in a browser.\n",
    "\n",
    "![title](media/nationalmuseum_page_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, an HTML page is a collection of HTML elements, where an element has the form:\n",
    "```<tagname> content </tagname>```.\n",
    "\n",
    "HTML elements can be nested with other HTML elements, meaning that the content between the start and end tags can be a set of elements.\n",
    "\n",
    "An HTML element can also have no content. In that case, it's simply a tagname, like this:\n",
    "```<tagname>```.\n",
    "\n",
    "Let's go through the elements in this page:\n",
    "- the ```<!DOCTYPE html>``` says that this document is an HTML document\n",
    "- the ```<html>``` element is the root element of an HTML page\n",
    "- the ```<body>``` element has the page content\n",
    "- the ```<h1>``` element is a large heading\n",
    "- the ```<h3>``` element is a smaller heading\n",
    "- the ```<p>``` element is a paragraph\n",
    "- the ```<br>``` element is a line break, which is an example of an element without content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to scrape the web\n",
    "\n",
    "Now let's go to the fun part!\n",
    "\n",
    "Going back to our movies database, you can see that there are some characters for which we're missing the character_name.\n",
    "You can try to query the database to find which are these characters, but in the meanwhile, we gathered them in file **../data/missing_character_names.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "# Import some helper functions to print shorter outputs\n",
    "import utils\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>actor_id</th>\n",
       "      <th>name</th>\n",
       "      <th>character_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073</td>\n",
       "      <td>718</td>\n",
       "      <td>tt0116405</td>\n",
       "      <td>82957</td>\n",
       "      <td>Dan Aykroyd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1218</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>105261</td>\n",
       "      <td>Bonnie Hunt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1219</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>79974</td>\n",
       "      <td>N'Bushe Wright</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>55658</td>\n",
       "      <td>Michael Rapaport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>57737</td>\n",
       "      <td>Denis Leary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  movie_id     imdb_id  actor_id              name  character_name\n",
       "0  1073       718  tt0116405      82957       Dan Aykroyd             NaN\n",
       "1  1218     17579  tt0120240     105261       Bonnie Hunt             NaN\n",
       "2  1219     17579  tt0120240      79974    N'Bushe Wright             NaN\n",
       "3  1220     17579  tt0120240      55658  Michael Rapaport             NaN\n",
       "4  1221     17579  tt0120240      57737       Denis Leary             NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_character_names = pd.read_csv('data/missing_character_names.csv')\n",
    "missing_character_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of a good way to get this missing data? An internet movie database seems like a very good candidate! Fortunately, the LDSA has got you covered.\n",
    "\n",
    "As an exercise, let's try to find Dan Aykroyd's character name in the movie with ID `tt0116405`. A quick internet search reveals that this movie is called **Getting Away With Murder**.\n",
    "\n",
    "The first thing to do is to open the web page that has the content we're interested in: **https://s02-infrastructure.s3.eu-west-1.amazonaws.com/ldsa_imdb/index.html#**\n",
    "\n",
    "It should look like this:\n",
    "\n",
    "<img src=\"media/imdb_movie_page.png\"/>\n",
    "\n",
    "Now, let's scroll down to the cast section of the page, since this is what we'll be scraping.\n",
    "\n",
    "<img src=\"media/imdb_cast.png\"/>\n",
    "\n",
    "In order to get the page's content, we'll use a GET request.\n",
    "\n",
    "We can get the content from the response, which will be... a bunch of incomprehensible HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html><html lang=\"en\">\\r\\n<head>\\r\\n<title>LDSA-IMDB</title>\\r\\n<meta charset=\"utf-8\">\\r\\n<link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"css/images/favicon.ico\">\\r\\n<link rel=\"stylesheet\" href=\"css/style.css\" type=\"text/css\" media=\"all\">\\r\\n<link rel=\"stylesheet\" href=\"css/colorbox.css\" type=\"text/css\" media=\"all\">\\r\\n</head>\\r\\n<body>\\r\\n<!-- wrapper -->\\r\\n<div id=\"wrapper\">\\r\\n  <div class=\"light-bg\">\\r\\n    <!-- shell -->\\r\\n    <div class=\"shell\">\\r\\n      <!-- header -->\\r\\n      <div class=\"header\">\\r\\n   '\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://s02-infrastructure.s3.eu-west-1.amazonaws.com/ldsa_imdb/index.html#\")\n",
    "\n",
    "\n",
    "# Printing short output, if you want to see everything, delete the friendly_print function call\n",
    "utils.friendly_print_string(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is where **Beautiful Soup** can help us. Beautiful soup is a package for parsing HTML documents. It allows us to break down HTML documents into smaller components, and extract the information we need. You can check its documentation [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "First, we need to create an instance of the BeautifulSoup class, passing it the HTML document to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the **prettify** method, we can see the HTML elements of the document in a pretty and indented way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   LDSA-IMDB\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <link href=\"css/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
      "  <link href=\"css/style.css\" media=\"all\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"css/colorbox.css\" media=\"all\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <!-- wrapper -->\n",
      "  <div id=\"wrapper\">\n",
      "   <div class=\"light-bg\">\n",
      "    <!-- shell -->\n",
      "    <div class=\"shell\">\n",
      "     <!-- header -->\n",
      "     <div class=\"\n"
     ]
    }
   ],
   "source": [
    "# Printing short output, if you want to see everything, delete the friendly_print function call\n",
    "utils.friendly_print_string(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the **children** property of the soup, we can parse it into smaller elements.\n",
    "\n",
    "We can see that this soup has two top-level elements:\n",
    "\n",
    "* a Doctype element, with the value 'html'.\n",
    "* a Tag element, with tag html.\n",
    "\n",
    "As we've seen before, the Doctype element simply indicates that our soup corresponds to an html document (a webpage).\n",
    "\n",
    "We're particularly interested in the `html` Tag element, which is where the actual HTML content is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.Tag]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_children = list(soup.children)\n",
    "\n",
    "# inspecting the types of the elements in the soup\n",
    "[type(item) for item in soup_children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the `html` tag element from the soup, we can just call it by its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>LDSA-IMDB</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<link href=\"css/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
       "<link href=\"css/style.css\" media=\"all\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"css/colorbox.css\" media=\"all\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "</head>\n",
       "<body>\n",
       "<!-- wrapper -->\n",
       "<div id=\"wrapper\">\n",
       "<div class=\"light-bg\">\n",
       "<!-- shell -->\n",
       "<div class=\"shell\">\n",
       "<!-- header -->\n",
       "<div class=\"header\">\n",
       "<!-- socials -->\n",
       "<div class=\"socials\"> <a class=\"facebook-ico\" href=\"#\">facebook-ico</a> <a class=\"twitter-ico\" href=\"#\">twitter-ico</a> <a class=\"you-tube-ico\" href=\"#\">you-tube-ico</a> </div>\n",
       "<!-- end of socials -->\n",
       "<h1 id=\"logo\"><a href=\"#\">LDSA-IMDB</a></h1>\n",
       "<!-- navigation -->\n",
       "<nav id=\"navigation\">\n",
       "<ul>\n",
       "<li><a href=\"#\">SHOW ALL</a></li>\n",
       "<li><a href=\"#\">LATEST MOVIES <span>20</span></a></li>\n",
       "<li><a href=\"#\">TOP RATED</a></li>\n",
       "<li><a href=\"#\">MOST COMMENTED</a></li>\n",
       "</ul>\n",
       "</nav>\n",
       "<!-- end of navigation -->\n",
       "<div class=\"cl\"> </div>\n",
       "</div>\n",
       "<!-- end of header -->\n",
       "<!-- main -->\n",
       "<div class=\"main\">\n",
       "<!-- content -->\n",
       "<section class=\"content\">\n",
       "<!-- post -->\n",
       "<div class=\"post\">\n",
       "<!-- post-inner -->\n",
       "<div class=\"post-inner\">\n",
       "<header>\n",
       "<h2><a href=\"#\">Getting Away With Murder</a></h2>\n",
       "<p class=\"tags\"><a href=\"#\">FAMILY</a> <a href=\"#\">COMEDY</a> <a href=\"#\">ANIMATION</a> </p>\n",
       "<div class=\"cl\"> </div>\n",
       "</header>\n",
       "<div class=\"img-holder\"> <a href=\"#\"><img alt=\"\" src=\"css/images/post-img.jpg\"/></a> <a class=\"btn-full-image popup\" href=\"css/images/post-img.jpg\"><span>FULL IMAGE</span></a> </div>\n",
       "<!-- meta -->\n",
       "<div class=\"meta\">\n",
       "<p class=\"date\">APRIL 09, 2012 by <a href=\"#\">JOHN DOE</a></p>\n",
       "<div class=\"right\">\n",
       "<div class=\"rating-holder\">\n",
       "<p>RATING</p>\n",
       "<div class=\"rating\"> <span style=\"width: 100%;\"></span> </div>\n",
       "</div>\n",
       "<a class=\"comments\" href=\"#\">59 comments</a> </div>\n",
       "<div class=\"cl\"> </div>\n",
       "</div>\n",
       "<!-- end of meta -->\n",
       "<!-- post-cnt -->\n",
       "<div class=\"post-cnt\">\n",
       "<p>\n",
       "                  A moral college ethics professor plans to kill his neighbor, a Nazi death camp commander.\n",
       "                </p>\n",
       "<div class=\"actor-list\">\n",
       "<p>Actor list</p>\n",
       "<div class=\"actor-info grid-container\">\n",
       "<div class=\"actor-portrait\"><img src=\"css/images/dan.jpg\" width=\"100%\"/></div>\n",
       "<div class=\"actor-data\">\n",
       "<p infotype=\"actor-name\">Dan Aykroyd</p>\n",
       "<p infotype=\"character-name\">Jack Lambert</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"actor-info grid-container\">\n",
       "<div class=\"actor-portrait\"><img src=\"css/images/lily.jpg\" width=\"100%\"/></div>\n",
       "<div class=\"actor-data\">\n",
       "<p infotype=\"actor-name\">Lily Tomlin</p>\n",
       "<p infotype=\"character-name\">Inga Mueller</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"actor-info grid-container\">\n",
       "<div class=\"actor-portrait\"><img src=\"css/images/jack.jpg\" width=\"100%\"/></div>\n",
       "<div class=\"actor-data\">\n",
       "<p infotype=\"actor-name\">Jack Lemmon</p>\n",
       "<p infotype=\"character-name\">Max Mueller</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<a class=\"more\" href=\"#\">CONTINUE READING</a> </div>\n",
       "<!-- end of post-cnt -->\n",
       "</div>\n",
       "<!-- post-inner -->\n",
       "</div>\n",
       "<!-- end of post -->\n",
       "<div class=\"pagination\">\n",
       "<ul>\n",
       "<li class=\"laquo\"><a href=\"#\"><span></span></a></li>\n",
       "<li class=\"active\"><a href=\"#\">1</a></li>\n",
       "<li><a href=\"#\">2</a></li>\n",
       "<li><a href=\"#\">3</a></li>\n",
       "<li><a href=\"#\">4</a></li>\n",
       "<li><a href=\"#\">5</a></li>\n",
       "<li class=\"raquo\"><a href=\"#\"><span></span></a></li>\n",
       "<li><a href=\"#\">10</a></li>\n",
       "<li class=\"dots\">. . .</li>\n",
       "<li><a href=\"#\">last</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</section>\n",
       "<!-- end of content -->\n",
       "<!-- sidebar -->\n",
       "<aside class=\"sidebar\">\n",
       "<div class=\"widget\">\n",
       "<h3 class=\"widgettitle\">Genres</h3>\n",
       "<ul>\n",
       "<li><a href=\"#\">Action</a></li>\n",
       "<li><a href=\"#\">Comedy</a></li>\n",
       "<li><a href=\"#\">Family</a></li>\n",
       "<li><a href=\"#\">History</a></li>\n",
       "<li><a href=\"#\">Mystery</a></li>\n",
       "<li><a href=\"#\">Sci-Fi</a></li>\n",
       "<li><a href=\"#\">War</a></li>\n",
       "<li><a href=\"#\">Western</a></li>\n",
       "<li><a href=\"#\">Adventure</a></li>\n",
       "<li><a href=\"#\">Crime</a></li>\n",
       "<li><a href=\"#\">Fantasy</a></li>\n",
       "<li><a href=\"#\">Horror</a></li>\n",
       "<li><a href=\"#\">Thriller</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"widget\">\n",
       "<h3 class=\"widgettitle\">Opening This Week</h3>\n",
       "<ul>\n",
       "<li><a href=\"#\">The Hunter Games <strong>$98 Mil</strong></a></li>\n",
       "<li><a href=\"#\">American Reunion <strong>$50 Mil</strong></a></li>\n",
       "<li><a href=\"#\">Titanic <strong>$23 Mil</strong></a></li>\n",
       "<li><a href=\"#\">Wrath of the Titans <strong>$50 Mil</strong></a></li>\n",
       "<li><a href=\"#\">Mirror Mirror <strong>$7 Mil</strong></a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"widget socials-widget\">\n",
       "<h3 class=\"widgettitle\">Get Connected</h3>\n",
       "<ul>\n",
       "<li><a class=\"facebook-ico\" href=\"#\"><span></span>Facebook</a></li>\n",
       "<li><a class=\"twitter-ico\" href=\"#\"><span></span>Twitter</a></li>\n",
       "<li><a class=\"linkedin-ico\" href=\"#\"><span></span>Linkedin</a></li>\n",
       "<li><a class=\"you-tube-ico\" href=\"#\"><span></span>Youtube</a></li>\n",
       "<li><a class=\"rss-ico\" href=\"#\"><span></span>RSS</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</aside>\n",
       "<!-- end of sidebar -->\n",
       "<div class=\"cl\"> </div>\n",
       "</div>\n",
       "<!-- end of main -->\n",
       "<div class=\"footer\">\n",
       "<nav class=\"footer-nav\">\n",
       "<ul>\n",
       "<li><a href=\"#\">Show All</a></li>\n",
       "<li><a href=\"#\">Latest Movies</a></li>\n",
       "<li><a href=\"#\">Top Rated</a></li>\n",
       "<li><a href=\"#\">Most Commented</a></li>\n",
       "</ul>\n",
       "</nav>\n",
       "</div>\n",
       "</div>\n",
       "<!-- end of shell -->\n",
       "</div>\n",
       "</div>\n",
       "<!-- end of wrapper -->\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can navigate through the tags contained inside the `html` tag, to get to any element in the page.\n",
    "\n",
    "Let's check out the title of the page. This is contained in the `title` tag.\n",
    "\n",
    "We can find it two levels below the `html` tag, inside the `head` tag: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>LDSA-IMDB</title>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this tag has no children tags. Its content is simply a string, which we can get by calling the **get_text** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LDSA-IMDB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you must be thinking that this is a somewhat complicated process, as it requires manually inspecting the HTML document and navigating through thousands of tags in order to find the interesting content in the middle of a big mess. And you're right!\n",
    "\n",
    "However, there is an easier way to access the interesting content directly.\n",
    "\n",
    "First, you need to open the **developer tools** of your browser, in the page you want to scrape.\n",
    "These are tools that allow you to look in greater detail at the content of the website and at the processes running in the background.\n",
    "\n",
    "Usually, you just have to right-click the page and select the \"Inspect\" option. \n",
    "If that's not the case, just Google \"How to open developer tools in *\\<your browser\\>*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_open.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The developer tools will open at the bottom or on the side of the window. We're only interested in the **Inspector** tool, which allows us to look at the HTML elements that correspond to the different parts of the page.\n",
    "\n",
    "After clicking on the small arrow (circled in red), you can click on any object in the page with your mouse, and you'll see the correspondent HTML element highlighted in the developer tools window. Similarly, if you hover over the HTML code in the Inspector window, the corresponding part of the page will be highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_actordiv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection, we can see that all the information about the actors/actresses is inside an element with tag **div** and **class** `actor-list`. The class of an HTML element can be useful to identify what its content might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_actorlist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect even further and notice that the `actor-list` div has three children. The children have two classes - `actor-info`and `grid-container` - which seem to indicate that each children contains information for a single actor.\n",
    "\n",
    "Drilling down a bit more, we notice that the `actor-info` div contains two children, with `div` tags and classes `actor-portrait`/`actor-data`.\n",
    "\n",
    "Finally inside `actor-data`, we can find two children with `p` tags. These elements don't have a class, but have an **attribute** with name `infotype` and value `actor-name`/`character-name`. Attributes can also be used to identify the content of an element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_actor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have arrived at the character names, which is exactly what we set out to discover!\n",
    "\n",
    "Let try to replicate this process using our _beautiful soup_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, call the soup's **find_all** method to find the div element with class `actor-list`(and make sure there's only one in this page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements found:  1\n"
     ]
    }
   ],
   "source": [
    "# pay attention to the underscore after class (class_) in the function's parameters.\n",
    "# this is because \"class\" is a Python keyword.\n",
    "actor_list = soup.find_all('div', class_=\"actor-list\")\n",
    "print(\"Number of elements found: \", len(actor_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now let's search for all children that have tag `div`, and the `actor-info` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 actors.\n",
      "\n",
      "<div class=\"actor-info grid-container\">\n",
      " <div class=\"actor-portrait\">\n",
      "  <img src=\"css/images/dan.jpg\" width=\"100%\"/>\n",
      " </div>\n",
      " <div class=\"actor-data\">\n",
      "  <p infotype=\"actor-name\">\n",
      "   Dan Aykroyd\n",
      "  </p>\n",
      "  <p infotype=\"character-name\">\n",
      "   Jack Lambert\n",
      "  </p>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_info = actor_list[0].find_all('div', class_='actor-info')\n",
    "\n",
    "# Checking out how many were found:\n",
    "print(f\"Found {len(actor_info)} actors.\\n\")\n",
    "\n",
    "# Checking out one of them\n",
    "print(actor_info[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks correct!\n",
    "\n",
    "Now, let's focus on the first actor - Dan Aykroyd - and discover the name of its character.\n",
    "\n",
    "For that, we simply have to look for the `<p>` children elements with attribute **infotype**=**character-name**. Since we're looking for a single children, we can use the `find` method:\n",
    "\n",
    "Since searching for children is recursive (meaning: it searches for immediate children, then children-of-children, and so on), we don't need to find the `actor-data` div first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p infotype=\"character-name\">Jack Lambert</p>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_name = actor_info[0].find('p', infotype='character-name')\n",
    "\n",
    "character_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the text using the `get_text` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jack Lambert'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_name.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found Dan Aykroyd's character in **Getting Away With Murder**, which is Jack Lambert!\n",
    "\n",
    "And the best part is that it will only take some minutes to get all the other character and actor names. You're invited to do that as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optional\n",
    "\n",
    "### 5.1 Scraping and the Law\n",
    "\n",
    "[This](https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/) is an interesting article about the subject, bottom line being: when scraping web pages, don't use a very high request rate, so that the owners of the website don't get angry.\n",
    "\n",
    "### 5.2 Scraping and JavaScript\n",
    "\n",
    "Sometimes, when scraping web pages, you'll need to navigate from one page to the other, click buttons, or take other actions that enter the JavaScript domain. In such cases, Beautiful Soup is not enough to fill your needs. If you find yourself in this position, take a look at [Selenium](https://www.seleniumhq.org/).\n",
    "\n",
    "### 5.3 Website changes\n",
    "\n",
    "One of the biggest difficulties regarding scraping is that if there are changes to the layout of the website you're trying to scrape, you will inevitably need to rewrite part (or all) of your scraping code. This is why, for learning purposes, we are scraping a website hosted by the LDSA. If you are feeling brave, try scraping the same information from the official IMDB movie page!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
