{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b6b75485105e36c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# BLU01 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "Attention Windows users: The grader will run on Linux, and using power shell statements will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0240afddd4fae69d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import hashlib # for grading purposes\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e0b4e1a40ebaaa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q1: Use a shell command to count lines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a3d2245d57305d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the total number of lines of files data/exercises/surfing.txt and data/exercises/body_boarding.txt\n",
    "# and store the result in variable count_total.  \n",
    "# There is more than one way to do this. Hint: concatenate both files.\n",
    "# count_total = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e69c6137e73d90c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '71ee45a3c0db9a9865f7313dd3372cf60dca6479d46261f3542eb9346e4a04d6'\n",
    "assert hashlib.sha256(str(count_total).encode()).hexdigest() == expected_hash, \"count_total is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now store in 2 variables the first third and the last third of the lines existent in file data/exercises/surfing.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14cf2619322a8763",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# NOT GRADED optional exercise!!\n",
    "# Add the first third and the last third of the lines to the variables first_third and last_third. \n",
    "# Make it work to any files using count_total_surfing/3 for instance in the bash commands\n",
    "# count_total_surfing = \n",
    "# first_third = ...\n",
    "# last_third = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-20d96111430874d4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test the first_third and last_third exercise by running the following (ungraded) asserts.\n",
    "assert first_third[-1][0] == 'o'\n",
    "assert last_third[0][0] == 'o'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e27cb8588bb5fd40",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q2: Read a file with specific delimiter\n",
    "\n",
    "Read file **data/exercises/surfing_sessions.csv** into a pandas DataFrame.\n",
    "\n",
    "First, you should preview the file using a shell command in order to find out the used delimiter, and other properties of this file.\n",
    "\n",
    "Then, you should use function read_csv to read the data into a DataFrame. The resulting DataFrame should have the last column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-942e0590467e20d9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a shell command to preview the data\n",
    "# ! ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Use function read_csv to read the data into a DataFrame\n",
    "# df2 = pd.read_csv(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0c275c9acaa9c74d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df2.loc[126903, 'location'] == 'Pupukea', \"df2 data is wrong\"\n",
    "assert set(df2.columns) == {'location', 'surfer', 'wave_power'}, \"df2 data is wrong\"\n",
    "assert len(df2) == 108, \"df2 data is wrong\"\n",
    "assert df2.index[0] == 146097, \"df2 data is wrong\"\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df2.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6f9efef818e4a83",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q3: Read a csv file with problems\n",
    "\n",
    "Read file **data/exercises/surfing_sessions_w_problems.csv** using function `read_csv`. Pay attention to the following:\n",
    "* remove all lines where the number of columns is different from the majority of lines.\n",
    "* use the first column as index\n",
    "* there are some inputs in the file that should be interpreted as NaN, make sure you select the right one when reading the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2771b707556c08d2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/surfing_sessions_w_problems.csv with read_csv\n",
    "# df3 = pd.read_csv(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-601b354802964776",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df3.loc[130395, 'wave_power']), \"df3 data is wrong\"\n",
    "assert df3.loc[126903, 'wave_power'] == 32.7, \"df3  data is wrong\"\n",
    "\n",
    "mean_wave_power = df3['wave_power'].mean()\n",
    "assert math.isclose(17.741, mean_wave_power, rel_tol=1e-3), \"df3 data is wrong\"\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df3.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cfd5a97b1c49a0e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q4: Repair a csv file after importing\n",
    "Read the same file **data/exercises/surfing_sessions_w_problems.csv** using function `csv.reader()`. But now, be sure you don't miss any lines with relevant information! \n",
    "\n",
    "* use csv module to import everything to a list of lists\n",
    "* create a df with only 4 meaningful columns and then \n",
    "* replace garbage values with NaN's \n",
    "* format the columns with the right type\n",
    "* set the index of the df to column `visit_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-119041388e17fb72",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/surfing_sessions_w_problems.csv using csv.reader() and add result to\n",
    "# lines = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# create a dataframe using the line list with only 4 columns\n",
    "# df4 = pd.DataFrame(...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# replace invalid values with nan (np.nan)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# set types per dataframe column (always use int64 when int's are needed)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# set a new index to the dataframe\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a42299f9047590d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df4.loc[130395, 'wave_power']), \"df4 content is wrong\"\n",
    "assert df4.loc[126340, 'wave_power'] == 38.6, \"df4 content is wrong\"\n",
    "\n",
    "mean_wave_power = df4['wave_power'].mean()\n",
    "assert math.isclose(19.626, mean_wave_power, rel_tol=1e-3), \"df4 content is wrong\"\n",
    "\n",
    "assert df4['surfer'].dtype == np.int64, \"df4 types are wrong\"\n",
    "assert df4['location'].dtype == object, \"df4 types are wrong\"\n",
    "assert df4['wave_power'].dtype == float, \"df4 types are wrong\"\n",
    "assert df4.index.dtype == np.int64, \"df4 types are wrong\"\n",
    "\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df4.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-389bc42fe462c70e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q5: Read a JSON file\n",
    "\n",
    "Read file **data/exercises/portugal_production_of_electricity_gwh.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c2125479f7e50e5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_production_of_electricity_gwh.json with read_json\n",
    "# df5 = read_json(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f085fa2cdad9319",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df5) == 23\n",
    "assert set(df5.columns) == {'Biomass', 'Geothermal power', 'Hydropower < 10MW', 'Hydropower > 10MW', \n",
    "                           'Photovoltaic', 'Total','Total renewables','Windpower','Year'}, \"df5 columns are wrong\"\n",
    "\n",
    "expected_hash = '48beaa4bb16f0656bb4e4d3abb5da6ff6a50b52be037354f8c33455a7534102e'\n",
    "assert hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest() == expected_hash, \"df5 content is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d4b970f55b3e427",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q6: Read an Excel file\n",
    "\n",
    "Read file **data/exercises/portugal_gas_emissions_per_year.xlsx** using function read_excel. Pay attention to the following:\n",
    "\n",
    "* you should grab the table \"Series\" in sheet \"metadata\"\n",
    "* use column 'Serie' as index\n",
    "* make sure you keep only the rows and columns with data\n",
    "* set the variable distinct_scales with the number of ... distinct scales found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017a7c31b0ddc38e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_gas_emissions_per_year.xlsx with read_excel\n",
    "# df6 = read_excel(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "#distinct_scales = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91d5f07e40585680",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert distinct_scales == 2\n",
    "assert isinstance(df6, pd.DataFrame)\n",
    "expected_hash = '60c3ad36f77e7366103fe36a3f551a0cde7d64e26d3102ddb8b953d6208a6006'\n",
    "assert hashlib.sha256(\n",
    "        df6.loc[\n",
    "            df6.index==\"Nitrogen oxides\", \n",
    "            \"Measure Unit\"][0].encode()\n",
    "    ).hexdigest() == expected_hash, \"df6 is wrong\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a7407517d4d92c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q7: Find the encoding of a file\n",
    "\n",
    "Find the encoding used in file **data/exercises/cities.csv**, using the method that was shown in the Learning Units.\n",
    "\n",
    "Then, read the data into a DataFrame, using the read_csv method and find the `City` characters that has distance equal to 2377."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6944fd63bb38d8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the encoding of file data/exercises/cities.csv\n",
    "# encoding = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Read the file into a DataFrame\n",
    "# df7 = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Find the name of the city with distance = 2377\n",
    "# city_found = .... (assign a string)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-687fb83c97e03355",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df7, pd.DataFrame)\n",
    "\n",
    "expected_hash_1 = '969aef39a1d4cb1c5928c774cd7a4e3ccfc064a18fbd43a70193a2631d8a122d'\n",
    "assert hashlib.sha256(encoding.encode()).hexdigest() == expected_hash_1, \"encoding is wrong\"\n",
    "\n",
    "expected_hash_2 = '22522b6940ec2bcc42ea98f55878bee105c27254c4340fbce9fbc951b5aed078'\n",
    "assert hashlib.sha256(city_found.encode()).hexdigest() == expected_hash_2, \"city_found is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d103dfae3d5e11fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q8: Import a Random Sample of a Big File\n",
    "\n",
    "Consider the file **data/exercises/world_percentage_of_literacy.tsv**. Let's imagine this file is really huge, with a lot of rows!  Read the file using a random sample of 10 rows. Count the actual lines with `wc` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb39107093dd73fb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv with wc and save the number of lines\n",
    "# in lines_in_file (as an integer), using \n",
    "# lines_in_file = ...\n",
    "# Notice that the header is not a line..\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# make parameter rows_to_skip equal to the lines you want to skip loading \n",
    "# don't forget: 10 rows should be fecthed\n",
    "# rows_to_skip = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Create a df8 dataframe with the sampled values\n",
    "# don't forget: you want to keep the header plus 10 rows in the new dataframe.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec15a8be42137a01",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# getting remaining list of countries, removing rows_to_skip from the file\n",
    "df_helper = pd.read_csv( \n",
    "    'data/exercises/world_percentage_of_literacy.tsv', \n",
    "    sep='\\t',\n",
    "    header=0 \n",
    ")\n",
    "\n",
    "total_indexes = list(df_helper.index)\n",
    "for s in rows_to_skip:\n",
    "    total_indexes.remove(s-1)\n",
    "\n",
    "expected_hash = '7559ca4a957c8c82ba04781cd66a68d6022229fca0e8e88d8e487c96ee4446d0'\n",
    "assert hashlib.sha256(str(lines_in_file).encode()).hexdigest() == expected_hash, \"lines_in_file are wrong\"\n",
    "assert isinstance(df8, pd.DataFrame)\n",
    "assert list(df8['Country'])==list(df_helper.iloc[total_indexes]['Country'])\n",
    "assert df8.shape[0]==10, \"df8 size is wrong\"\n",
    "\n",
    "expected_hash = '4a44dc15364204a80fe80e9039455cc1608281820fe2b24f1e5233ade6af1dd5'\n",
    "assert  hashlib.sha256(str(df8.shape[0]).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e07a7b2cacd9d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q9: Loading a Big File\n",
    "\n",
    "Read file **data/exercises/world_percentage_of_literacy.tsv** using chunks keep only the columns `Country` and `Gender difference`.\n",
    "Note that:\n",
    "* file should be read by chunks of 20 countries\n",
    "* the missing values should be removed (filtered in each chunk)\n",
    "* the `Gender difference` should be converted to type float (in each chunk)\n",
    "* the index should be incremental starting from 0 (i.e, you don't need to read any column as the index)\n",
    "\n",
    "At the end, calculate the average `Gender difference`\n",
    "\n",
    "Tip: Be sure you investigate the data you are about to load before doing any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5106c25a705296e8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the chunks should be appended in a list called chunk_arr\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df9 should be the final dataframe with concatenated chunks\n",
    "# Resulting average should go on lit_avg variable\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f60a22c3465d5b83",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'cc63c8d6f0f9a8260d40b5c9a62d4fce5b693bab5750c90fd1f038ff64e37d6d'\n",
    "assert hashlib.sha256(str([len(c) for c in chunk_arr]).encode()).hexdigest() == expected_hash, \"error on chunk_arr sizes\"\n",
    "\n",
    "assert df9.loc[df9['Country']=='World', 'Gender difference'].values[0] == 7.3, \"df9 data is wrong\"\n",
    "assert df9.dtypes['Country'] == object, \"df9 structure is wrong\"\n",
    "assert df9.dtypes['Gender difference'] == float, \"df9 structure is wrong\" \n",
    "\n",
    "expected_hash = 'c4d7d45402099baaea8a079580a4ef950016ef7403178f72e64ceb3738e4471d'\n",
    "assert hashlib.sha256(str(lit_avg).encode()).hexdigest() == expected_hash, \"lit_avg is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e990312f7cddd0b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q10: Calculate average values of `Literacy All` using chunks and avoiding a complete data frame in memory.\n",
    "\n",
    "Using chunks, read file **data/exercises/world_percentage_of_literacy.tsv**, avoid incomplete rows and calculate the average of ***Literacy rate (all)*** without loading all data simultaneously. \n",
    "\n",
    "Use a similar approach of the previous question but don't create any dataframe neither any list with chunks; ***Hint: Use the average definition***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fd7700885246eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the final average should be in the variable final_avg\n",
    "# You should increment 2 variables in each chunk and use them at the end to calculate final_avg. call them lit_a, lit_b\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0edcf1260d7886c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(83.24370860927154, final_avg, rel_tol=1e-1), \"final_avg is wrong\"\n",
    "assert lit_b==151 or lit_a==151, \"lit_a or lit_b is wrong\"\n",
    "assert int(lit_b) == 12569 or int(lit_a)==12569, \"lit_a or lit_b is wrong\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
