{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU11 - Learning Notebook - Part 2 of 2 - Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, load_npz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-based recommendations\n",
    "\n",
    "**Memory-based recommenders** use previous interactions to predict the interest of a given user in a particular item, in a personalized way.\n",
    "\n",
    "The primary assumption is that **users' preferences are stable over time** and, thus, the user likes are similar to those he liked in the past.\n",
    "\n",
    "In the last notebook, we applied **collaborative filtering** to our problem, one of the most widely adopted personalized recommenders.\n",
    "\n",
    "However, due to **the cold-start problem**, our approach may be limited in the face of a limited community that needs to onboard new players and games (and thus have a low number of ratings to start with)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommenders\n",
    "\n",
    "It's time to get back to the whiteboard. üñäÔ∏è\n",
    "\n",
    "You remember that you have metadata about the items ‚Äî time to explore the `metadata.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content():\n",
    "    df = pd.read_json(os.path.join(os.path.join('data', 'metadata.json')), orient='index')\n",
    "    df = (df.rename(columns={\"ID\": \"VideoGameID\"})\n",
    "            .set_index('VideoGameID')\n",
    "            .sort_index())\n",
    "    return df[['Name', 'Genres', 'Description']]\n",
    "\n",
    "\n",
    "item_content = read_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the item metadata into a dataframe, hoping we can use it, somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoGameID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007 Legends</td>\n",
       "      <td>[Action, Shooter]</td>\n",
       "      <td>Gamers and Bond aficionados alike will become ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0RBITALIS</td>\n",
       "      <td>[Simulation, Indie]</td>\n",
       "      <td>0RBITALIS is a satellite launching simulator w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1... 2... 3... KICK IT! (Drop That Beat Like a...</td>\n",
       "      <td>[Action, Indie]</td>\n",
       "      <td>&lt;p&gt;Battle your favorite drum &amp;#39;n&amp;#39; bass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Second Ninja</td>\n",
       "      <td>[Action, Indie]</td>\n",
       "      <td>Ninjas are cool, this is an established fact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10,000,000</td>\n",
       "      <td>[Action, RPG, Casual, Indie, Puzzle]</td>\n",
       "      <td>&lt;p&gt;10000000 is a Dungeon Crawling RPG Matching...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Name  \\\n",
       "VideoGameID                                                      \n",
       "0                                                  007 Legends   \n",
       "1                                                    0RBITALIS   \n",
       "2            1... 2... 3... KICK IT! (Drop That Beat Like a...   \n",
       "3                                              10 Second Ninja   \n",
       "4                                                   10,000,000   \n",
       "\n",
       "                                           Genres  \\\n",
       "VideoGameID                                         \n",
       "0                               [Action, Shooter]   \n",
       "1                             [Simulation, Indie]   \n",
       "2                                 [Action, Indie]   \n",
       "3                                 [Action, Indie]   \n",
       "4            [Action, RPG, Casual, Indie, Puzzle]   \n",
       "\n",
       "                                                   Description  \n",
       "VideoGameID                                                     \n",
       "0            Gamers and Bond aficionados alike will become ...  \n",
       "1            0RBITALIS is a satellite launching simulator w...  \n",
       "2            <p>Battle your favorite drum &#39;n&#39; bass ...  \n",
       "3            Ninjas are cool, this is an established fact o...  \n",
       "4            <p>10000000 is a Dungeon Crawling RPG Matching...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we have `Genres` and `Description`. **We should be able to incorporate this information into our recommender.**\n",
    "\n",
    "You focus on genres, for now. What about a $I \\times G$ matrix, $P_I$, containing **item profiles**, where $g \\in G$ is a genre from the set of all possible genres? Assume there are $n$ items and $w$ genres.\n",
    "\n",
    "$$P_I = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, w}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, w}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{n, 1} & p_{n, 2} & \\dots & p_{n, w}\\end{bmatrix}$$\n",
    "\n",
    "Values, $p_{ig}$, would represent **whether, or how much, a given genre, $g$, is present in the item, $i$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "The first step, then, would be **feature extraction** to generate descriptive representations from the item metadata.\n",
    "\n",
    "Given the item profiles outlined above, we need to create the matrix $P_I$. Ideas? Think NLP. üìÑ\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You hypothesize that **genres, $g$, that occur less frequently might be more descriptive**.\n",
    "\n",
    "We denote the raw frequency counts, i.e., the number of times that $g$ occurs in $i$, as $f_{ig}$. It is known as **term frequency**. \n",
    "\n",
    "In our case, a genre can occur at most once per item (i.e., boolean frequency), but in many cases, things can be different, e.g., imagine if users could assign genres to games.\n",
    "\n",
    "We also use the **inverse document frequency**. Take __n__ as the total number of items and $|\\{i \\in I : g \\in i\\}|$ as the number of items that contain $g$, i.e., $f_{ig} \\neq 0$, it is given by:\n",
    "\n",
    "$$f'_{g} = log\\frac{n}{|\\{i \\in I : t \\in i\\}|}$$\n",
    "\n",
    "The more items that contain a given genre, the **lower the inverse document frequency**. We can use it to **adjust frequency counts** to **give extra weight to low-frequency genres**.\n",
    "\n",
    "Hence, we can compute the **TF-IDF (Term's Frequency - Inverse Document Frequency)** for a given genre $g$ for item $i$ as: \n",
    "\n",
    "$$p_{ig} =  f'_g \\cdot f_{ig}$$\n",
    "\n",
    "We interpret it as how much of $g$ there is in $i$, adjusted for rarity, i.e., the rarer, the better.\n",
    "\n",
    "# Building the item profiles\n",
    "\n",
    "To build the item profiles, we use the convenient `TfidfVectorizer` ([docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)) provided by `sklearn`.\n",
    "\n",
    "Since **the transformer is prepared to receive strings** (and not lists), we need to do some Pandas magic to convert the lists to strings and remove spaces to **reduce multi-word genres to a single string**, e.g., \"massivelymultiplayer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres = item_content['Genres'].apply(\";\".join).str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we apply the transformer. We verify that **it returns a sparse matrix**, which is excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5155x19 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **inspect the complete list of genres** at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'adventure',\n",
       " 'arcade',\n",
       " 'boardgames',\n",
       " 'card',\n",
       " 'casual',\n",
       " 'educational',\n",
       " 'family',\n",
       " 'fighting',\n",
       " 'indie',\n",
       " 'massivelymultiplayer',\n",
       " 'platformer',\n",
       " 'puzzle',\n",
       " 'racing',\n",
       " 'rpg',\n",
       " 'shooter',\n",
       " 'simulation',\n",
       " 'sports',\n",
       " 'strategy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item profiles beyond genre\n",
    "\n",
    "The item profiles **describe the content of the item according to relevant attributes**. Why only use the genre, then? You generalize your definition to include any content or tag, $t \\in T$.\n",
    "\n",
    "Take $t \\in T$ to be one of $w$ tags that describes the content of a given item, the item profiles,$P_I$, are a $I \\times T$ matrix, as:\n",
    "\n",
    "$$P_I = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, w}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, w}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{n, 1} & p_{n, 2} & \\dots & p_{n, w}\\end{bmatrix}$$\n",
    "\n",
    "Given the above, you decide to **take advantage of the game descriptions as well**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = item_content['Description'] + genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **concatenate the descriptions with the genres** and **fit the transformer on the result**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5155x33710 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 688709 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_profiles = vectorizer.fit_transform(all_content)\n",
    "item_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a much larger and richer matrix with, hopefully, **more descriptive power**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take another approach if we want to take into consideration each column independently. For that, we can combine the information from both columns by appending, horizontally, the result from vectorization applied to each column, `Description`, and `Genres`, individually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "genre_profile = vectorizer.fit_transform(genres)\n",
    "description_profile = vectorizer.fit_transform(item_content['Description'])\n",
    "item_profiles_ = np.hstack([genre_profile.toarray(), description_profile.toarray()])\n",
    "item_profiles_ = csr_matrix(item_profiles_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, for this case, we will use the first approach, where we append all the columns in one single string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# User profiles\n",
    "\n",
    "Item profiles are not enough to provide personalized recommendations, as they do not consider the taste of the user.\n",
    "\n",
    "You realize that, so far, you have users represented according to their interactions with items, in the ratings matrix, $R$, and items represented according to the attributes in $P_I$. Is there a way to conciliate both representations, so that **users and items are in the same space**?\n",
    "\n",
    "We must be able to **uncover user preferences** for attributes, $P_U$, a $U \\times T$ matrix:\n",
    "\n",
    "$$P_U = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, w}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, w}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{m, 1} & p_{m, 2} & \\dots & p_{m, w}\\end{bmatrix}$$\n",
    "\n",
    "We don't have this data explicitly available, i.e., on a silver plate (but almost). But **you realize you can compute it**, as: \n",
    "\n",
    "$$P_U = R \\cdot P_I$$\n",
    "\n",
    "## What kind of wicked magic is that? \n",
    "\n",
    "Because the product of $R$, a $m \\times n$ matrix, by $P_I$, $n \\times w$, is a $m \\times w$ matrix, where \n",
    "**each element is a dot-product of user ratings by item attributes**:\n",
    "\n",
    "$$p_{u, t} = r_u \\cdot p_t = \\sum\\limits_{i=1}^n r_{u, i}p_{i, t}$$\n",
    "\n",
    "The **$r_u$ stands for a row of the ratings matrix**, i.e., a user, and **$p_t$ stands for a column of the items profile matrix**, i.e., an attribute.\n",
    "\n",
    "In other words (i.e., more legible üòÑ), it's as if we are propagating the user rating of item $i$ to its attributes. \n",
    "\n",
    "A good rating to $i$, is a good rating to all attributes of $i$, i.e., **if the user likes $i$ we assume he likes the content of $i$**.\n",
    "\n",
    "However, can it be? Let's give it some thought. \n",
    "\n",
    "For visual clarity, we will use the convention of **$r_{u,}$ to represent a row of the ratings matrix** and **$p_{,t}$ for columns of the item profiles matrix**:\n",
    "\n",
    "$$P_U = R \\cdot P_I = \\begin{bmatrix}r_{1,} \\cdot p_{,1} & r_{1,} \\cdot p_{,2} & ... & r_{1,} \\cdot p_{,w} \\\\ r_{2,} \\cdot p_{,1} & r_{2,} \\cdot p_{,2} & ... & r_{2,} \\cdot p_{,w} \\\\ ...  & ... & ... & ...\\\\ r_{m,} \\cdot p_{,1} & r_{m,} \\cdot p_{,2} & ... & r_{m,} \\cdot p_{,w}\\end{bmatrix}$$\n",
    "\n",
    "Armed with this knowledge, we can now **calculate the user profiles**.\n",
    "\n",
    "## Build the user profiles\n",
    "\n",
    "The first step, therefore, is to load the ratings matrix, $R$, created in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12393x5155 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 128804 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = load_npz(os.path.join('data', 'ratings_matrix.npz'))\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use `dot` to **compute the dot product between the ratings matrix and the item profiles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12393x33710 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6539426 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_user_profiles(R, item_profiles):\n",
    "    return np.dot(R, item_profiles)\n",
    "\n",
    "\n",
    "user_profiles = make_user_profiles(R, item_profiles)\n",
    "user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note this point again:* learning the user profiles requires the product of two matrices! No need for super-advanced maths!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "\n",
    "The prediction step is different when compared to collaborative filtering. First, recap. What do we have?\n",
    "\n",
    "* $P_I$, an items-attributes, $I \\times T$, matrix with item profiles\n",
    "* $P_U$, a users-attributes, $U \\times T$, matrix with user profiles.\n",
    "\n",
    "What do we want? To know **what items best match the user taste**. \n",
    "\n",
    "Therefore, given that items and users are represented in the same space (same features/columns), **we can use the cosine distance to identify which items are closer to the user profile**. Take **$p^T_i$ and $p^T_u$ to represent a row of the item and user profiles matrices, respectively**:\n",
    "\n",
    "$$sim(p^T_u, p^T_i) = cos(\\theta) = \\frac{p^T_u \\cdot p^T_i}{||p^T_u||||p^T_i||}$$\n",
    "\n",
    "Again, we use `sklearn` to compute the similarities for us, as:\n",
    "\n",
    "$$sim(P_U, P_I) = \\frac{P_U \\cdot P_I}{||P_U||||P_I||}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12393x5155 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60252254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(R, item_profiles, user_profiles):\n",
    "    \n",
    "    preds = cosine_similarity(user_profiles, item_profiles)\n",
    "    \n",
    "    # Exclude previously rated items.\n",
    "    preds[R.nonzero()] = 0\n",
    "    \n",
    "    return csr_matrix(preds)\n",
    "\n",
    "\n",
    "content_preds = make_predictions(R, item_profiles, user_profiles)\n",
    "content_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that, at this point, we obtain **a matrix of predictions with the same shape as the previous one**, generated with collaborative filtering.\n",
    "\n",
    "As we can see, **we have a little fewer predictions using content-based recommendations, but it is normal to get more predictions. It just happens that we have a very populated ratings matrix in this dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05687734142964063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparsity(matrix):\n",
    "    return 1 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])\n",
    "\n",
    "\n",
    "sparsity(content_preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we are making predictions **grounded in meaningful content attributes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "We can now **apply the filtering techniques (best-item, top-$N$) on the first notebook** directly to generate content-based recommendations.\n",
    "\n",
    "To exemplify, we test the **same** best-item implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 857],\n",
       "       [  29],\n",
       "       [3872],\n",
       "       ...,\n",
       "       [ 983],\n",
       "       [1337],\n",
       "       [1337]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_item(pred):\n",
    "    return np.negative(pred).toarray().argsort()[:, :1]\n",
    "\n",
    "\n",
    "get_best_item(content_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, **let's check what the corresponding game to the first prediction** is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoGameName    Cities XL Platinum\n",
       "Name: 857, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_games = pd.read_csv(os.path.join('data', 'video_games.csv'), index_col='VideoGameID')\n",
    "video_games.loc[857]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the gist, content-based recommenders will **allow us to make recommendations even in the face of the cold-start problem**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
