{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12bea12324c032d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose, assert_almost_equal\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f07b8631beb0508c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q1. S&P 500 Companies\n",
    "\n",
    "For the first question, you will be making use of regex. In particular, you have a list of companies currently in the S&P 500, their [stock tickers](https://en.wikipedia.org/wiki/Ticker_symbol) (an abbreviation used to uniquely identify publicly traded shares of a particular stock on a particular stock market), and their industries, and you'll have to answer some very specific questions about that list.\n",
    "\n",
    "Start by loading the data into a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c533ada39c512c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/SP500.txt\"\n",
    "companies = []\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    companies = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ecb61cd23d78a49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check the format\n",
    "companies[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25dda75958bdaef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the first item, for example, `3M Company` is the company name, `MMM` is the ticker symbol, and `Industrials` is the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df341d1f1838c29e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.a)\n",
    "\n",
    "First, we want to know which companies belong to the Real Estate or Health Care sectors. Return the full strings that include these companies in a list assigned to a variable `ans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cddd8e2e48afb31",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ans = [ ... ]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5a358ed83c473214",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans) == 93\n",
    "assert hashlib.sha256(' '.join(ans).encode()).hexdigest() == \\\n",
    "    'b25ef38e29cc7d975a651e93fc201b9a83cfdb35a0a79d6068d1e29325d3fa8f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e3cc736b933d71e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.b)\n",
    "\n",
    "Next, find the companies that start with an initial consisting of a capital letter followed by a period (e.g. `A.`). Return a list of the companies (the full strings) in the variable `ans_initials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bf14a2df3dd3e4e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ans_initials = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-19b61469674be299",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of companies starting with an initial: \" , len(ans_initials))\n",
    "assert 'A.O. Smith Corp (AOS) -- Industrials' in ans_initials\n",
    "assert 'D. R. Horton (DHI) -- Consumer Discretionary' in ans_initials\n",
    "assert 'Arthur J. Gallagher & Co. (AJG) -- Financials' not in ans_initials\n",
    "assert 'Berkshire Hathaway (BRK.B) -- Financials' not in ans_initials\n",
    "assert hashlib.sha256(' '.join(ans_initials).encode()).hexdigest() == \\\n",
    "    '999cbcf37711021cecdda234015f87d8785f0d25f1200d43be4cf0ac7239aaa7'\n",
    "assert len(ans_initials) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6727f8213243afc0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.c)\n",
    "\n",
    "Now, extract only the company names whose stock tickers contain just a single letter. For example, if the string looks like `Lisbon Data Science Academy (L) -- Education`, return just `Lisbon Data Science Academy`. Store the company names as a list called `ans_single`.\n",
    "\n",
    "For an extra challenge, try to do this using just one regex pattern. You may want to use `re.search()` and read about [capturing groups](https://docs.python.org/3/howto/regex.html#grouping), and don't forget you can use tools like https://regex101.com/ to test your regexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-447eb675481e47fd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ans_single = [ ... ]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-535072609d84d577",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_single) == 10\n",
    "assert hashlib.sha256(' '.join(ans_single).encode()).hexdigest() == 'b449c503fabbec88da870a63b6bda074496741113d7c04f204ad597a31ca23fb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0409818769bbf3d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q2. Sports News (preprocessing)\n",
    "\n",
    "Here is a subset of data taken from the 20 Newsgroups dataset, a classic text classification dataset, which we can download directly from [scikit-learn](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset). To keep things simple, we will only be focusing on two of the categories, `rec.sport.baseball` and `rec.sport.hockey`. Our goal will be to classify whether news articles are about the sport of baseball or hockey.\n",
    "\n",
    "First, let's prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5684ea0f3e42ccee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is how the data was originally downloaded\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# categories = [\n",
    "#  'rec.sport.baseball',\n",
    "#  'rec.sport.hockey',\n",
    "# ]\n",
    "\n",
    "# # returns a list of strings X representing the articles to classify, and the category labels y as a numpy array\n",
    "# X, y = fetch_20newsgroups(subset=\"all\", remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "#                           categories=categories, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the data from pickle files instead\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"data/20_newsgroups_baseball_hockey_X.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(\"data/20_newsgroups_baseball_hockey_y.pkl\", \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbdc0548dd699460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check the data size and distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_stats(X, y):\n",
    "    print(f\"Size of dataset: {len(X)}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Distribution of classes: {dict(zip(unique, counts))}\")\n",
    "\n",
    "get_data_stats(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-808b90ccd21d360d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since the classes are evenly distributed, we can use a regular train/dev/test split. We'll use a dev and test size of 10% of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a524119b37972d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train dev test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(f\"Train size: {len(X_train)}\\nDev size: {len(X_dev)}\\nTest size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e93f9088c1da685e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since the goal is to turn the strings on X into useful features, now we will be performing common preprocessing operations on the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-addc0c904c359402",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.a)\n",
    "\n",
    "First tokenize the data. Implement the function to receive a list of strings and an NLTK-style tokenizer, and return the list but with tokenized strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b7930a61806e32",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings that is the tokenization of the given data by applying the given tokenizer.\n",
    "    E.g. for an input [\"This is a test!\", \"No, it can't be\"],\n",
    "      it returns [\"This is a test !\", \"No , it can ' t be\"]\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings containing the text to tokenize\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f829c5a222c54690",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "data_tok = apply_tokenizer(X_train, tokenizer)\n",
    "\n",
    "assert len(data_tok) == 1594\n",
    "assert len([w for s in data_tok for w in s.split(\" \")]) == 333566\n",
    "assert hashlib.sha256(data_tok[1234].encode()).hexdigest() == \\\n",
    "    'bd70c45292aafb1430f3dae58dd7b3732ff2ddebc8acb64976a38efbe7945215'\n",
    "assert hashlib.sha256(data_tok[567].encode()).hexdigest() == \\\n",
    "    '0de358e31d950ef321b2f3d762b525a8ab1e65e0a2c392633e6984e40253f2e4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b76d100b971a777f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.b)\n",
    "\n",
    "The second step you will implement is lowercasing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee47fb5a45fbd622",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with all the tokens lowercased.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to be lowercased\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7979e12840663ea2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc = apply_lowercase(data_tok)\n",
    "\n",
    "assert len(data_tok_lc) == 1594\n",
    "assert len([w for s in data_tok_lc for w in s.split(\" \")]) == 333566\n",
    "assert hashlib.sha256(data_tok_lc[1234].encode()).hexdigest() == \\\n",
    "    'e12bd8bec884721329792d49085e8e6b268c8129da7ed638b06ccdf3ea49c7a5'\n",
    "assert hashlib.sha256(data_tok_lc[567].encode()).hexdigest() == \\\n",
    "    '4476776aa3ea52c7580c592bfeb0e2286a79ec1bb615188518a167a73429b424'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8044c14c20583cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.c)\n",
    "\n",
    "Now implement a function that filters the stopwords. We will use NLTK's built-in English stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f0dea2c5108c93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ecb29c8fe117f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, where the strings do not contain any of\n",
    "        the stopwords in the given list.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to filter stopwords from\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the stopwords from the text\n",
    "    # data_no_stopwords = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return data_no_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f70da0255ea6e291",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw = apply_filter_stopwords(data_tok_lc, stopword_list)\n",
    "assert len(data_tok_lc_nosw) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw for w in s.split(\" \")]) == 239401\n",
    "assert hashlib.sha256(data_tok_lc_nosw[1234].encode()).hexdigest() == \\\n",
    "    '9d48d50a7a0dcd3676c13419750a3aad75006e165d2c614e0fe7e8f98d521b84'\n",
    "assert hashlib.sha256(data_tok_lc_nosw[567].encode()).hexdigest() == \\\n",
    "    'd1d745ba13b4588eb2356dd3a5119113e391bfe226bc4126338391bf03830ecf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d0cb317596faa2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.d)\n",
    "\n",
    "After filtering stopwords, we want to remove punctuation from the text as well. Make use of `string.punctuation` to do so. Make sure to remove all punctuation and not only distinct tokens that only contain punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0cd3cf5cc97a8f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with no punctuation.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings from which to remove punctuation\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31c9a6a65413aef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw_nopunct = apply_filter_punct(data_tok_lc_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925e418acc339a2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Normalize whitespaces\n",
    "\n",
    "Run the following function on `data_tok_lc_nosw_nopunct` before checking your answers, in case extra whitespaces cause the asserts to fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67539c50de422305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(data):\n",
    "    return [re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text) for text in data]\n",
    "\n",
    "data_tok_lc_nosw_nopunct_norm = normalize_whitespace(data_tok_lc_nosw_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-650a677a3a01d1bf",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(data_tok_lc_nosw_nopunct_norm) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm for w in s.split(\" \")]) == 174486\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[1234].encode()).hexdigest() == \\\n",
    "    '57b0c8646701140d4edfb7112b812c0df7cdebfe7db1a58811c9229f906f6ca9'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[567].encode()).hexdigest() == \\\n",
    "    'a39ba5c27525d163573d484284aff0228118db129aeae1623020ac11b063a952'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38d66dd89731e114",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.e)\n",
    "\n",
    "The last preprocessing step you are going to implement is stemming. Implement the function to receive an NLTK-style stemmer and return the text as a string with the stemmer applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a831ba989f3e50e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with stemmed data.\n",
    "    \n",
    "    Args:\n",
    "    data - list with text to stem\n",
    "    stemmer - instance of stemmer to use\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3596a6510ebbda3d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "data_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(data_tok_lc_nosw_nopunct_norm, stemmer)\n",
    "\n",
    "assert len(data_tok_lc_nosw_nopunct_norm_stem) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm_stem for w in s.split(\" \")]) == 174486\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[1234].encode()).hexdigest() == \\\n",
    "    'f8e83239a3658073219232f17c270a0df20d4cebfb517ce935d395e02467009f'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[567].encode()).hexdigest() == \\\n",
    "    '4f36be21767ee2ad747baecf0d67b8b082c8c65f334fce896036870a75570fb0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bfe5aed6ebdbb26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.f)\n",
    "\n",
    "Finally, join everything in a function, that applies the steps in the following order:\n",
    "* Tokenization\n",
    "* Lowercasing\n",
    "* Filtering stopwords\n",
    "* Filtering punctuation\n",
    "* Normalizing whitespace\n",
    "* Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b2305431c20dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, lower=True, remove_punct=True, stopwords=[], stemmer=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        self.stopwords = stopwords\n",
    "    \n",
    "    def clean_sentences(self, data):\n",
    "                \n",
    "        # Split sentence into list of words\n",
    "        # sentences_preprocessed = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Lowercase\n",
    "        if self.lower:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        if self.stopwords:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        # sentences_preprocessed = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return sentences_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a4c1aa16cea2ffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    lower=True, \n",
    "    remove_punct=True, \n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")\n",
    "\n",
    "X_train_pre = text_cleaner.clean_sentences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4a87d0c9b1f20f7e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(X_train_pre) == 1594\n",
    "assert len([w for s in X_train_pre for w in s.split(\" \")]) == 174486\n",
    "assert X_train_pre[1234] == (\"mcgwire carter see justif bond thoma tend higher bat averag major differ \"\n",
    "    \"see mcgwire carter carter draw walk pitcher afraid throw strike carter\")\n",
    "assert X_train_pre[567] == (\"best one saw last year willi mcgee matthew think philli fierc line \"\n",
    "    \"drive still rise hit second deck facad vet willi mcgee one homerun last year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48abbdab8acc3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q3. Text classification\n",
    "\n",
    "We will now use what we've learned to try to classify the topic of these articles as baseball or hockey. Let's first load the preprocessed data (slightly different from the answer to Q2) and double-check the balance of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cfef332c9bd3d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    \"\"\"\n",
    "    Loads a tsv file with the label in the first column and the text in the second column.\n",
    "    Returns two lists, one containing only the text and one containing the labels\n",
    "    \n",
    "    Args:\n",
    "    file_name: path to input file\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    texts = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            labels.append(int(label))\n",
    "            texts.append(text)\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99de6cc5a4a3ff52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, y_train = load_dataset('data/sports_train_preprocessed.tsv')\n",
    "X_dev_pre, y_dev = load_dataset('data/sports_dev_preprocessed.tsv')\n",
    "X_test_pre, y_test = load_dataset('data/sports_test_preprocessed.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfca3c5348fd2262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aaf6fbf5dbc51f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_dev_pre, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e5147de37fa0351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So, we should be aiming for much better than 53% accuracy, which is what we would get if we naively predicted `1` (hockey) for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a844631e7326ff6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.a)\n",
    "\n",
    "First, we'll look at the top X ngrams in each category to see if anything is interesting. Write a function that returns the top n ngrams of the data, limited to a given label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36567f8f392a4836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_ngrams_for_category(text, labels, filter_label, top_n=10, ngram_size=1):\n",
    "    \"\"\"\n",
    "    Filters the data to the desired label, constructs a counter of ngrams\n",
    "    Returns the top n ngrams\n",
    "    \n",
    "    Args:\n",
    "    text: list of text strings to get ngrams from\n",
    "    labels: categories corresponding to text\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    top_n: top n ngrams to return\n",
    "    ngram_size: the \"n\" in ngram (e.g. if ngram_size=2, return only bigrams)\n",
    "    \"\"\"\n",
    "    # First, filter text to desired category\n",
    "    # text_filtered = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Create list of ngrams\n",
    "    # ngram_list = ...\n",
    "    # hint: make the ngrams in the list an immutable data type so they can be used as dict keys later,\n",
    "    # tuples for example\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Count occurances of each ngram\n",
    "    # hint: use collections.Counter\n",
    "    # ngram_counter = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # return top_n most common ngrams\n",
    "    # return ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca0190cfba4ad83",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_10_unigrams_baseball = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_baseball == [(('0',), 1899),\n",
    "                                     (('1',), 718),\n",
    "                                     (('game',), 561),\n",
    "                                     (('year',), 505),\n",
    "                                     (('2',), 481),\n",
    "                                     (('3',), 453),\n",
    "                                     (('5',), 408),\n",
    "                                     (('would',), 383),\n",
    "                                     (('4',), 342),\n",
    "                                     (('one',), 311)]\n",
    "top_7_bigrams_baseball = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=7, ngram_size=2)\n",
    "assert top_7_bigrams_baseball == [(('0', '0'), 240),\n",
    "                                 (('last', 'year'), 118),\n",
    "                                 (('1', '0'), 94),\n",
    "                                 (('0', '1'), 72),\n",
    "                                 (('new', 'york'), 66),\n",
    "                                 (('00', '00'), 66),\n",
    "                                 (('1', '2'), 61)]\n",
    "top_10_unigrams_hockey = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_hockey == [(('0',), 5104),\n",
    "                                     (('1',), 3657),\n",
    "                                     (('2',), 2571),\n",
    "                                     (('3',), 1804),\n",
    "                                     (('4',), 1569),\n",
    "                                     (('6',), 1159),\n",
    "                                     (('5',), 1135),\n",
    "                                     (('7',), 989),\n",
    "                                     (('game',), 972),\n",
    "                                     (('team',), 743)]\n",
    "top_5_trigrams_hockey = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=5, ngram_size=3)\n",
    "assert top_5_trigrams_hockey == [(('0', '0', '0'), 691),\n",
    "                                 (('0', '1', '1'), 422),\n",
    "                                 (('1', '0', '1'), 303),\n",
    "                                 (('1', '0', '0'), 184),\n",
    "                                 (('1', '1', '0'), 171)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05f81b8870270b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looking at the top ngrams for each category, it doesn't seem like a BoW model will be very interesting, but let's try anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a096ee6776427b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.b)\n",
    "To begin, let's streamline our pipeline in a nice function. We'll use sklearn's `CountVectorizer` instead of the function we wrote. We'll also use the `MultinomialNB` classifier to make predictions on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af90809e6c74e780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(X_train, X_dev, y_train, y_dev, ngram_range=(1,1), max_features=None):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the pipeline containing the countvectorizer and the multinomial NB classifier\n",
    "    # text_clf = Pipeline(...)\n",
    "    \n",
    "    # Train the classifier\n",
    "    # (...)\n",
    "\n",
    "    # y_dev_pred = (...)\n",
    "    # print the classification report\n",
    "    # acc = (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    # return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97ba1cceed5a53f9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "# check same as before\n",
    "assert_allclose(clf['clf'].intercept_, np.array([-0.68084531]), rtol=1e-3)\n",
    "assert ' '.join(str(i) for i in y_dev_pred[:20]) == \"0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0\"\n",
    "assert hashlib.sha256(' '.join(str(i) for i in y_dev_pred).encode()).hexdigest() == \\\n",
    "    \"5e67c5da0e5fc28a5d834ee9f12b93bc7c20bd26347fc9f02a36d50bc000b573\"\n",
    "assert_allclose(acc, 0.91, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7678b7610a7200f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c7cbbc0c3275557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So just with the simplest BoW model we already get an F-score of 0.91! But let's see if we can do even better... In the misclassified examples, the last one even contains the word \"hockey\" but was misclassified. And slightly tricker, but the first example contains the team name \"Anaheim Ducks,\" which is an NHL team. We should be able to get those right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4fd66e62c165a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.c)\n",
    "Run the pipeline for different ngram ranges and/or with different values for max_features, until you get an accuracy of at least 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e75ac8652cc7e741",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf,y_dev_pred, acc = train_and_validate(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-722d1b4ff466bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc >= 0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af52f1de74f79623",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# look at some misclassified examples again\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711b6cc0145d445c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Depending on your chosen hyperparameters, the 2 examples we missed earlier that we should have gotten should be correct now! But let's see if we can get even better performance now by using the relative importance of ngrams with TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28921443e50007c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4. TF-IDF\n",
    "\n",
    "Similarly to how we found the top ngrams before we started working with BoW, we will now find the most important unigrams, inverse weighted by document frequency.\n",
    "\n",
    "#### Q4.a)\n",
    "\n",
    "First, implement TF-IDF on a dataframe representing a Bag of Words model of the data. Here is a reminder of the TF-IDF formula:\n",
    "\n",
    "$$ tfidf _{t, d} =(log_2{(1 + tf_{t,d})})*(log_2{(1 + \\frac{N}{df_{t}})})  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start you off with the BoW representation, in pandas dataframe format\n",
    "vec = CountVectorizer()\n",
    "BoW_train = vec.fit_transform(X_train_pre)\n",
    "BoW_train_df = pd.DataFrame(BoW_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b915bab713aba13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(BoW_df):\n",
    "    \"\"\"\n",
    "    Returns pandas dataframe of a tfidf representation from a BoW representation dataframe.\n",
    "\n",
    "    Args:\n",
    "    BoW_df - dataframe with document word counts (Bag of Words)\n",
    "    \"\"\"\n",
    "    # remember that the BoW representation is raw counts, it is not normalized by the length of each text\n",
    "    # first transform the df into term frequencies, where the counts are normalized\n",
    "    # also double check the formula above for additional transformations applied to the tf expression\n",
    "    # use np.log2(x) for base-2 log\n",
    "    # tf = (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # now we need a function that computes the idf side of the expression\n",
    "    # it operates over a column (a word in the vocab), where the column contains each doc's count of that word\n",
    "    # def _idf(column):\n",
    "    #   return (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # now weight the term frequencies by the idfs\n",
    "    # tf_idf = (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86090d8867691e1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = tfidf(BoW_train_df)\n",
    "assert math.isclose(tfidf_df[12609][2], 0.1223836, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df[0][1531], 0.03629635, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df[8][6], 0.019335965, abs_tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b)\n",
    "\n",
    "Now that we have our TF-IDF representation, we can proceed with getting the most important words per category. \n",
    "\n",
    "Let's write a small helper function first to get the vocabulary in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocab from CountVectorizer, which is of the format {\"word\": idx, ...}\n",
    "vocab_word_2_idx = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4cf0289cdb72e49a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# write a function to convert this vocab to the format {idx: \"word\", ...}\n",
    "\n",
    "def reverse_vocab(vocab_word_to_index):\n",
    "    \"\"\"\n",
    "    Converts a vocabulary dictionary with words as keys and indices as values to a \n",
    "        new dictionary with indices as keys and words as values\n",
    "    \n",
    "    Args:\n",
    "    vocab_word_to_index: vocabulary dict of the format {\"word\": 0, \"hello\": 1, ...}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c86ba6062add631",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab_idx_2_word = reverse_vocab(vocab_word_2_idx)\n",
    "assert len(vocab_idx_2_word) == 12613\n",
    "assert vocab_idx_2_word[11714] == \"two\"\n",
    "assert vocab_idx_2_word[2847] == \"boston\"\n",
    "assert vocab_idx_2_word[8762] == \"palmer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.c)\n",
    "\n",
    "Finally, write a function to return the N most important words in a single category according to TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00f14b79ff68d32e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_tfidf_words_for_category(tfidf_df, labels, filter_label, vocabulary, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns the top n most important words for the given label, with the given vocabulary\n",
    "    and corresponding tfidf representation of some text data\n",
    "    \n",
    "    Args:\n",
    "    tfidf_df: a dataframe of the tfidf representation of some text (columns=words, rows=documents)\n",
    "    labels: categories corresponding to documents in tfidf_df\n",
    "    filter_label: the label to filter the data on before getting top n words\n",
    "    vocabulary: a dict of the format {idx: \"word\", ...}\n",
    "    top_n: top n words to return\n",
    "    \"\"\"\n",
    "    # First, filter tfidf to desired category\n",
    "    # tfidf_filt = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Get the top n words of the current label, according to tfidf\n",
    "    # There are several ways to do this, but here are some hints\n",
    "    # 1) Sum the filtered df to get the total value per word\n",
    "    # 2) Sort\n",
    "    # 3) Replace indices with words and return the top_n\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b51198b450763c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_15_hockey = top_tfidf_words_for_category(tfidf_df, y_train, 1, vocab_idx_2_word, top_n=15)\n",
    "assert top_15_hockey == ['game',\n",
    "     'team',\n",
    "     'hockey',\n",
    "     'play',\n",
    "     'would',\n",
    "     'player',\n",
    "     'playoff',\n",
    "     'go',\n",
    "     'one',\n",
    "     'year',\n",
    "     'nhl',\n",
    "     'get',\n",
    "     'espn',\n",
    "     'like',\n",
    "     'goal']\n",
    "top_20_baseball = top_tfidf_words_for_category(tfidf_df, y_train, 0, vocab_idx_2_word, top_n=20)\n",
    "assert top_20_baseball == ['game',\n",
    "     'year',\n",
    "     'basebal',\n",
    "     'pitch',\n",
    "     'hit',\n",
    "     'run',\n",
    "     'would',\n",
    "     'think',\n",
    "     'pitcher',\n",
    "     'one',\n",
    "     'know',\n",
    "     'cub',\n",
    "     'day',\n",
    "     'like',\n",
    "     'first',\n",
    "     'time',\n",
    "     'anyon',\n",
    "     'go',\n",
    "     'team',\n",
    "     'get']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a8bfb9ad7d5ec44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, these top words per category make a lot more sense than the ones from just BoW. Maybe this will help us make better predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2672054e4024a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.d)\n",
    "\n",
    "Now, we will put everything together. Rewrite the train_and_validate function from Q3.b but using sklearn's `TfIdfTransformer`. Also, add kwargs for CountVectorizer's `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02453bb681cd33b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate_with_tfidf(X_train, X_dev, y_train, y_dev, ngram_range=(1,1),\n",
    "                                  max_features=None, max_df=1.0, min_df=1):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    max_df = max_df for CountVectorizer (int or float)\n",
    "    min_df = min_df for CountVectorizer (int or float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the pipeline containing the countvectorizer and the multinomial NB classifier\n",
    "    # text_clf = Pipeline(...)\n",
    "    \n",
    "    # Train the classifier\n",
    "    # (...)\n",
    "\n",
    "    # y_dev_pred = (...)\n",
    "    # print the classification report\n",
    "    # acc = (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    # return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee1c189fe642928a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate_with_tfidf(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "assert hashlib.sha256(\" \".join([str(x) for x in list(y_dev_pred)]).encode()).hexdigest() == \\\n",
    "    \"1beda6d3a1226853b58518db5f7fcba362722f1f97b53f0af5c71c53fc28f686\"\n",
    "assert_allclose(acc, 0.93367, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ada9070ceb8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since \"outfield\" is clearly a baseball word, let's keep going and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab54cc6297c36ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q4.e)\n",
    "\n",
    "Use the `train_and_validate_with_tfidf` function you created before to train with different hyperparameters and get an accuracy score above 94% on the validation dataset. (This threshold is the same as what we got for plain CountVectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b6f3694941ac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf, _, acc = train_and_validate_with_tfidf(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-07b6f3694941ac81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc > 0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = clf['tfidf'].transform(clf['vect'].transform(X_test_pre))\n",
    "y_test_pred = clf['clf'].predict(X_test_vec)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4aa5fa0188b8ce3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We ended up not being able to beat our baseline of BoW with TF-IDF, maybe because the dataset is small and very easy, and so a simple algorithm was enough. Still, in general, it's good to try TF-IDF for text classification tasks and have an understanding of how your results change with different hyperparameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
