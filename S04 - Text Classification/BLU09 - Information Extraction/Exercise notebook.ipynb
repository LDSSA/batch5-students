{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a3dc8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f881c7002cca9b48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU09 - Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125f899",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4efa4dd0f5a58872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing needed packages here\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def _hash(s):\n",
    "    return hashlib.sha256(\n",
    "        bytes(str(s), encoding='utf8'),\n",
    "    ).hexdigest()\n",
    "\n",
    "cpu_count = int(os.cpu_count()) if os.cpu_count() != None else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9f847",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a882aedc21b3fc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this learning unit you are going to tackle with a quite real problem: **Detecting fake news!** Let's create a binary classifier to determine if a piece of news is considered 'reliable' or 'unreliable'. You will start by building some basic features, then go on to build more complex ones, and finally putting it all together. You should be able to have a working classifier by the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255edbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b947ffb2b30ff870",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset we will be using is the [Fake News](https://www.kaggle.com/c/fake-news/overview) from Kaggle. Each piece of news is either reliable or trustworthy, '0', or unreliable and possibly fake, '1'. First, let's load it up and see what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4d9f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62fce116d684ff08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"datasets/fakenews/train.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df[\"title\"] = df[\"title\"].astype(str)\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "df = df[:5000]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40814b45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38f5eb775841d955",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that we have 4 columns that are pretty self-explanatory, let's drop the author column since we only want to practice our text analysis, drop title as well for simplicity sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118e6f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4555d789c2c7417",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"author\", \"title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313691e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f6782b20750823",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's also load Spacy's model with merged entities (which will come in handy later) and stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"merge_entities\", after=\"ner\")\n",
    "en_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "# Let's get the text of the news article processed by SpaCy - This might take a while depending on \n",
    "#   your hardware (a break to walk the dog? üê∂)\n",
    "docs = list(tqdm(nlp.pipe(df[\"text\"], batch_size=20, n_process=cpu_count-1), total=len(df[\"text\"])))\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b2a9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f9871459d26c91a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Overall, the text looks good! Not too many errors, well written... as expected from a news article. Fake news is a very tough, recent problem that is now appearing more and more frequently in the wild, usually there aren't many ortographic mistakes or slang (as it may happen with spam - another text classification problem!) since it's coming from news sources that want to be/appear credible but also clickbaity so they can profit on that good ad revenue and create distrust.\n",
    "\n",
    "Nevertheless, it is always good to process any textual information in order to normalize it, remove stopwords and punctuation so we can extract the most important parts of the text.\n",
    "\n",
    "\n",
    "## Q1. Text Cleaning\n",
    "\n",
    "#### Q1.a)\n",
    "\n",
    "With our new previously acquired knowledge, let's remove any stopwords and punctuation from our text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e65b8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-abf9a07be796f9b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Hint: Remember the good old RegEx from 2 LUs ago\n",
    "        how can I just remove everything except words, digits and spaces?\n",
    "    \"\"\"\n",
    "    \n",
    "    # text = re.sub(...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    \"\"\"\n",
    "    Hint: You may want to split the text into tokens using the tokenizer, it might help when searching for stopwords\n",
    "        If you do, do not forget to join the tokens afterwards!\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Return the full string again here\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f49efb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5f05f229186c7541",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed[\"text\"] = df_processed[\"text\"].apply(remove_punctuation)\n",
    "    assert _hash(df_processed[\"text\"].values) == \"9c34086ca91f5845a1069878dd4fd7fcf54826bdf02a0240f644b78257b73137\", \\\n",
    "        \"it appears you are not removing all of the punctuation, read the hint üòâ.\"\n",
    "    \n",
    "    \n",
    "    df_processed[\"text\"] = df_processed[\"text\"].apply(remove_stopwords, stopwords = en_stopwords)\n",
    "    assert _hash(df_processed[\"text\"].values) == \"e10c9b012ef768908431c03fdc7bf0ae6b11cd2004397f93a9bd262b5d432b8f\", \\\n",
    "        \"something wrong with removing stopwords, read the hints!\"\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "df_processed = preprocess_text(df)\n",
    "assert df_processed.shape == (5000, 2), \"something is wrong with the shape of the dataframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0634e62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2777339c1d76131e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1.b)\n",
    "\n",
    "With our text processed, let's get a baseline model for our classification problem! Let's use our comfortable _TfidfVectorizer_ to get a simple, fast and trustworthy baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900b1d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1cf7d1d751604527",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_with_tfidf(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # pipe = (...)\n",
    "    # pipe.fit(...)\n",
    "    # (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return pipe, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b79669",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c345c9379c620ae2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_processed[\"text\"], df_processed[\"label\"], \n",
    "                                                    test_size=0.2, random_state=42, stratify=df_processed[\"label\"])\n",
    "baseline_model, baseline_acc = baseline_with_tfidf(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# asserts\n",
    "assert isinstance(baseline_model, Pipeline)\n",
    "assert _hash(baseline_model[0]) == \"5d9dc3620e12f84e4f957a7b00db14e15ebcc5d20cbc1f883940318fbb5442d5\", \"Something\\\n",
    "is wrong! Use the default parameters!\"\n",
    "assert _hash(baseline_model[1]) == \"7ab1fd7f03f247b36ba389a0a2eb8767ed2f1d2535f8e295669ac5ae2319d3c8\", \"Something\\\n",
    "is wrong! Use the default parameters!\"\n",
    "assert np.allclose(baseline_acc, 0.908, 0.01), \"something wrong with the accuracy score. Use the default parameters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc804ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ecc682a6b13cabf4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Wow, the accuracy is quite good for such a simple text model! This just proves that, a starting trustworthy baseline is all you need. I can't stress enough that it's really important to have a simple first iteration, and afterwards we can add complexity and study which features do make sense or not, testing more out of the box solutions. \n",
    "\n",
    "Sometimes, data scientists focus right off the bat on the most complex solutions and a simple one would be enough. Real life problems will obviously achieve lower scores as the datasets are not controlled or cleaned for you but that should not stop you from starting with a simpler and easier solution.\n",
    "\n",
    "Now let's see if adding new features we can still improve our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3f611",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9acda58125c99fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2. SpaCy Matcher\n",
    "\n",
    "Let's see if we can extract some useful features by using our SpaCy Matcher.\n",
    "\n",
    "#### Q2.a) Simple Matcher\n",
    "\n",
    "You think of some words that could be related with the detection of Fake News. Something starts ringing in your mind about \"propaganda\", \"USA\" and \"fraud\", so you decide to check how many of those words appear in our news articles using the SpaCy Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f158c1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca5f9a618bc32ee6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "words = [\"propaganda\", \"USA\", \"fraud\"]\n",
    "\n",
    "# init the matcher - remember it from the learning notebook\n",
    "# add the patterns of the words. HINT: for a direct match you need a specific pattern (check SpaCy docs)\n",
    "# count how many matches!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# count = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6002d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-57893459c2e5a1ac",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert _hash(count) == \"47fec9f491173c57c1d5b35dfefdb69cba6bd61bfbadea64015a65120efa15a0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374a2f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9a8e7ce0cab87fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2.b) POS-Tagging Search\n",
    "\n",
    "Your head is still working new theories. You start thinking that, fake news might exaggerate on adjectives and adverbs by sharing exaggerated or over the top descriptions. So you decide to create a feature that counts the number of _Adjectives_ and _Adverbs_ in a piece of news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170ff4c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d048ae4dde4a43cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# HINT: you already have your news text processed (the docs variable),\n",
    "# so you can go over every doc and check if there is any POS Tag which is an ADJ or ADV\n",
    "# to check the POS tag of a token in a doc -----> token.pos_\n",
    "\n",
    "\"\"\"\n",
    "Try it out by running the below code! \n",
    "for token in docs[0]:\n",
    "    print(token.pos_)\n",
    "\"\"\"\n",
    "\n",
    "# Return a list with the number of adjectives and adverbs for every piece of news in docs\n",
    "# nb_adj_adv = [...]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618744a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3961c5c5cb9b18aa",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(nb_adj_adv) == list, \"the variable should be a list with just 1 dimension.\"\n",
    "assert len(nb_adj_adv) == 5000, \"the length of the array is wrong. You should have a count for every news article.\"\n",
    "\n",
    "value_hash = \"2488c9b42fd6efc018e0857683cc782347c4a09763a5d94579ca41425d4b6f64\"\n",
    "assert _hash(nb_adj_adv) == value_hash\n",
    "df_processed[\"nb_adj_adv\"] = nb_adj_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74452de0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e54363f2d61151f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2.c) Entity Search\n",
    "\n",
    "Another theory that might be worth testing is that people and organizations are often involved in this kind of news. Nowadays, a lot of fake news are often shared by these to justify or divert attention to/from their actions. You think that, another smart feature could be to analyse if there are any known identities (people and/or organizations) that might be closely related with fake news.\n",
    "\n",
    "In order to do this, you decide to create a Matcher that searches for _People_ and identifies which are the ones that appear most frequently in our piece of news. **Let's find the top 10!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fe123",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a5547e1de72b597",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# I'll reset the matcher for you\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# pattern = [...] to find people entities\n",
    "# matcher.add(\"\", pattern)\n",
    "\n",
    "# for doc in docs:\n",
    "# do matches and save the text in a list\n",
    "\n",
    "# count the number of times the same Person appears on the list (hint: remember the dictionary solution...)\n",
    "# only take the top 10 of the counter! THE RESULT SHOULD BE A LIST\n",
    "\n",
    "# most_common_ents = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de656a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a55276f7a5cb1f58",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(most_common_ents) == list, \"the output is not a list\"\n",
    "assert len(most_common_ents) == 10, \"It should be the highest 10 people!\"\n",
    "\n",
    "value_hash = \"95983e691298df0238a6d47e54fff172a5166924dfdad865a3ce4f6ac6c52cf6\"\n",
    "assert _hash(most_common_ents) == value_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943cdd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7c9dcb2ac4fd3aff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Well, now I'm curious to see who is on the top 10. Since this dataset is from the USA, I think we can already deduce who is going to show up in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32b64a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c68d93893da9985e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "most_common_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3e265",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5c997aef8ff2a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As expected, we have some known names here. The matcher was also able to detect full names and join then in a single occurrence (when they appeared together in the sentence). This was only possible since we called the following line\n",
    "\n",
    "`nlp.add_pipe(\"merge_entities\", after=\"ner\")`\n",
    "\n",
    "before processing the documents with SpaCy. If we didn't, every name would be considered independent even when belonging to the same person.\n",
    "\n",
    "We can also check how many times do these people appear for each label of news!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e5cfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c52187cad7e360a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for person, _ in most_common_ents:\n",
    "    print(person)\n",
    "    print(df[df['text'].str.contains(\"\")].label.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79678441",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5de1f6e3a47a8db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the distribution it might not be a useful feature at all :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244da23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59afa572e05bc308",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3. Feature Unions\n",
    "\n",
    "Now the only thing missing is to create a Feature Union that allows us to join the features we have so far and see if we can actually improve our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10835e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61e270fd37131ec7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca16469",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-692f18d2b61996fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.a) Adding Extra Features\n",
    "\n",
    "First off, there are some simple features that we can extract from the dataset to try and to enrich our model! Let's add to our dataframe the following features: **number of words in the doc**, **length of the doc** and **average word length**. Remember we already have the **number of adjectives and adverbs** that we also want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb93e53",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6910256a13fa82fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# df_processed[\"nb_words\"] = ...\n",
    "# df_processed[\"doc_length\"] = ...\n",
    "# df_processed[\"avg_word_length\"] = ...\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5b354",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-31106be84628e3c9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_processed.shape == (5000, 6), \"Something wrong about the shape, do you have all columns/rows?\"\n",
    "assert \"nb_words\" in df_processed, \"Missing column! Maybe wrong name?\"\n",
    "assert \"doc_length\" in df_processed, \"Missing column! Maybe wrong name?\"\n",
    "assert \"avg_word_length\" in df_processed, \"Missing column! Maybe wrong name?\"\n",
    "\n",
    "hash_nb_words = \"bbd0f5a5179c2e0433c3cfd2bf5809c4db8f3b7dfdf44a6729c79c9337ff2361\"\n",
    "hash_doc_length = \"3fa5e413714a16c6c9b463ff9883f366dd8fd8e4e46812bdb589365b4afbe54d\"\n",
    "hash_avg_word_length = \"9c11f12992d183e81f7c20ebc3e901fc4b2ef56ab01d2d2046f0603f70abb043\"\n",
    "\n",
    "assert _hash(df_processed[\"nb_words\"]) == hash_nb_words, \"Something wrong with how you are calculating this column.\"\n",
    "assert _hash(df_processed[\"doc_length\"]) == hash_doc_length, \"Something wrong with how you are calculating this column.\"\n",
    "assert _hash(df_processed[\"avg_word_length\"]) == hash_avg_word_length, \"Something wrong with how you are calculating this column.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1e3de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b12d83fd4d036457",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### Q3 b) Feature Union\n",
    "\n",
    "Let's create a processing _Pipeline_ for every new feature and then join them all using a _Feature Union_. For the textual feature use the usual _TfidfVectorizer_ with default parameters and for any numerical feature use a _Standard Scaler_. Afterwards, join the features pipelines using a _Feature Union_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e0bf1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a5c8a9abba2b5e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# text_pipe = Pipeline([...])\n",
    "# nb_adj_adv_pipe = Pipeline([...])\n",
    "# nb_words_pipe = Pipeline([...])\n",
    "# doc_length_pipe = Pipeline([...])\n",
    "# avg_word_length_pipe = Pipeline([...])\n",
    "# feats = FeatureUnion(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bc439",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-98151e411b73b1f5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(feats, FeatureUnion)\n",
    "assert len(feats.transformer_list) == 5, \"Are you creating 5 pipelines? One for each feature?\"\n",
    "for pipe in feats.transformer_list:\n",
    "    \n",
    "    selector = pipe[1][0]\n",
    "    if not (isinstance(selector, TextSelector) or isinstance(selector, NumberSelector)):\n",
    "        raise AssertionError(\"pipeline is wrong, the Selectors should come first.\")\n",
    "        \n",
    "    feature_builder = pipe[1][1]\n",
    "    if not (isinstance(feature_builder, TfidfVectorizer) or isinstance(feature_builder, StandardScaler)):\n",
    "        raise AssertionError(\"pipeline is wrong, the second thing to come should be the Tfidf or the Scaler.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb7c8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8c92614d69d640a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's build our function to use our newly created _Feature Union_ and calculate its performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431c958",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb15cc415e6737d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def improved_pipeline(feats, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    Don't forget to add the feats to the Pipeline!\n",
    "    \"\"\"\n",
    "    \n",
    "    # pipe = (...)\n",
    "    # pipe.fit(...)\n",
    "    # (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return pipe, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da0430",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-873e3b1b663a7b12",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Y = df_processed[\"label\"]\n",
    "X = df_processed.drop(columns=\"label\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "pipeline_model, pipeline_acc = improved_pipeline(feats, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# asserts\n",
    "assert isinstance(pipeline_model, Pipeline)\n",
    "assert _hash(pipeline_model[0]) == \"f5e738d891cee945082226770873c560481fccce687af07ea966b30de065ac35\", \"The first part of the\\\n",
    "Pipeline is incorrect.\"\n",
    "assert _hash(pipeline_model[1]) == \"7ab1fd7f03f247b36ba389a0a2eb8767ed2f1d2535f8e295669ac5ae2319d3c8\", \"The second part of the\\\n",
    "Pipeline is incorrect.\"\n",
    "assert np.allclose(pipeline_acc, 0.896, 0.03), \"something wrong with the accuracy score. Use the default parameters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e0258",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec9f67cb4f0f5b43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With this more complex approach we have achieved a very similar performance when compared to our baseline. This might mean a lot of things: our features might have no real revelance to the model (which you will learn how to check later on with some feature importance) or we have achieved a plateau and can't improve the score with the this technique. \n",
    "\n",
    "Nevertheless it is a good score for this problem and dataset. Regardless you have learnt a lot about _POS Tagging_, _Entities_, _Feature Union_ and also leant that the sky is the limit when creating features. anything can be a feature really - now good features are a totally different thing that might need more research and validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
