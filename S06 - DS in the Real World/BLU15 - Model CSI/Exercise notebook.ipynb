{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a634852",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bac5c183fed6655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU15 - Model CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4779b21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96cd08680b07fd21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import joblib\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "# for evaluation purposes\n",
    "import hashlib\n",
    "from plotchecker import LinePlotChecker, ScatterPlotChecker, BarPlotChecker\n",
    "\n",
    "def _hash(s):\n",
    "    return hashlib.blake2b(\n",
    "        bytes(str(s), encoding='utf8'),\n",
    "        digest_size=5\n",
    "    ).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cba64a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8649ce0b822858ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the previous BLUs we've been working with the _\"Velho Banco\"_ dataset, with the goal of design a system that tries to predict if a given individual earns more than 50K a year. \n",
    "\n",
    "As a reminded, each row in the dataset is about a client, and here's the attibute information:\n",
    "\n",
    "    1) age \n",
    "    2) workclass - type of work performed by client (eg. `Private`)\n",
    "    3) fnlwgt - chest pain type (4 values)\n",
    "    4) education - level of education of client (eg. `Bachelors`)\n",
    "    5) education-num - \n",
    "    6) marital-status - client's marital status (eg `Widowed`)\n",
    "    7) occupation - type of job held by client (eg. `Craft-repair`)\n",
    "    8) relationship - \n",
    "    9) race - client's race\n",
    "    10) sex - \"male\"/\"female\"\n",
    "    11) capital-gain - total capital gain in previous year\n",
    "    12) capital-loss - total capital loss in previous year\n",
    "    13) hours-per-week - number of hours the client works per week\n",
    "    14) native-country - client's original nationality (eg. `Portugal`)\n",
    "\n",
    "Your original dataset is located in `data/bank.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c539659",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f86e818301e9e0fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recently your client has just provided you with a new set of observations, located in `data/bank_new_observations.csv`. This is your goal:\n",
    "\n",
    "- Assess how your model performs with the new dataset\n",
    "- Assess if there has been any changes to the data \n",
    "- Deploy a new model\n",
    "\n",
    "**Note:** Your first step of **assessing how your original model performs with the new dataset** will be ungraded as, in fear of spoiling the fun of solving BLU14 on your own, we'll be skipping this step. ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ceb3b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ca6bb39f0e31c29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Start by loading the old and new data and have a quick look at it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd645b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a5d9ea7d542b8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    df = pd.read_csv(os.path.join(\"data\", file))\n",
    "    return df\n",
    "df_original = load_data(\"bank.csv\")\n",
    "df_new = load_data(\"bank_new_observations.csv\")\n",
    "target='salary'\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4709bc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-137881b8963bcb30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f4a93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d6bc9ccdc9e68e88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One of the most important things is to check if the data has changed over time. This data is not timestamped, so the approach we'll be following is to check if the distribution has changed from one dataset to the other. Let's begin!\n",
    "\n",
    "**Important note about the grading**\n",
    "Grading plots is difficult! We are using [`plotchecker`](https://github.com/jhamrick/plotchecker) to grade the plots with `nbgrader`. For `plotchecker` to work with nbgrader, we need to add on each cell, the line\n",
    "\n",
    "```\n",
    "axis = plt.gca();\n",
    "````\n",
    "\n",
    "After the code required to do the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72aa1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7230e5aeecd1dab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "Start by building a funtion to plot the histogram of a given feature for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89005ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d38810c26a6f6b3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_distribution_histogram(dataframe, \n",
    "                                    column_name, \n",
    "                                    title, x_axis_label, y_axis_label,\n",
    "                                    label_name,\n",
    "                                    number_bins = 15):\n",
    "    \"\"\"\n",
    "    This function generates a histogram.\n",
    "    Args:\n",
    "        dataframe:\n",
    "        column_name: String. Name of the column whose distribution we\n",
    "        want to visualize.\n",
    "        title: String. Title of the histogram.\n",
    "        x_axis_label: String. X-axis label.\n",
    "        y_axis_label: String. Y-axis label.\n",
    "    Outputs:\n",
    "        Histogram containing distribution for specific column column_name.\n",
    "    \"\"\"\n",
    "    #plt.hist(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    plt.legend(loc='upper right')\n",
    "    axis = plt.gca();\n",
    "    return axis\n",
    "\n",
    "axis = generate_distribution_histogram(df_new, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e04b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2a86e98ad84f32e7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pc = BarPlotChecker(axis)\n",
    "l = [pc.xlabel] + [pc.ylabel]\n",
    "l.sort()\n",
    "\n",
    "assert _hash(pc.title) == 'b5c996841f', \"Did you set the right title?\"\n",
    "assert _hash(l) in ['2867b32d42'], \"Did you set the right variables for the plot axes?\"\n",
    "try:\n",
    "    pc.assert_num_bars(15)\n",
    "except:\n",
    "    \"Did you set the right number of bins?\"\n",
    "assert _hash(pc.centers) == 'c705138d5b' and _hash(pc.heights) == '2e4053a844', \"Did you set the right variable or the right plot type?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8ddf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c700286f49dcbaa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.2\n",
    "Let's use the same code to look at the \"Age\" variable of the new and original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b5f59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16ad1e9b7eb15d73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "axis = generate_distribution_histogram(df_original, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'Original data')\n",
    "axis = generate_distribution_histogram(df_new, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'New data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76af75f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05177050f00f7e93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Do you think there was a change in the distribution? Answer with `\"yes\"` or `\"no\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166d349",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bce97fde5dcd36b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer_1_2 = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326961f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-221bb1b584d9dd11",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert _hash(answer_1_2.lower()) == '0fe736fa82', \"Look again!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f9ed6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2dadef9a85dc3be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "How sure are you about your answer to the previous question? Odds are that you picked the option that passed the assert. ;) That's why statistics is here! \n",
    "\n",
    "As we covered in the learning notebook, the K-S Statistic is a useful tool to check if the upcoming new data belongs to the same distribution as that of training data. Let's use this instead.\n",
    "\n",
    ">If the K-S statistic p-value is high (>0.05), then we cannot reject the hypothesis that the distributions of the two samples are the same.\n",
    "\n",
    "**hint:** We need the [stats.ks_2samp](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html) test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522bddb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fe5c5c130ff4717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_ks_test(feature, training_df, new_df):\n",
    "    \"\"\"\n",
    "    This function returns the result of the k-s statistic for the same feature in two datasets.\n",
    "    Args:\n",
    "        feature: feature name\n",
    "        training_df: dataframe used to train the model\n",
    "        new_df: dataframe with the new data\n",
    "    Outputs:\n",
    "        P-value of the K-S statistic for feature in training_df and new_df\n",
    "    \"\"\"\n",
    "    #pvalue = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pvalue\n",
    "    \n",
    "pvalue = get_ks_test('age', df_original, df_new)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f83a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b69f4b8e2335fbe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pvalue, float), \"are you returning just the p-value?\"\n",
    "assert math.isclose(pvalue, 0.9331, abs_tol=.01), \"Something is wrong. are you returning the p-value or the the k-s test value? we want the first\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc84a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2685fbad657f66f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With a p-value as high as this, it's pretty safe to say that for the age, there has been no difference in the distribution of values. What about the other features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70444d33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30d76e50782846f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "Using the function above, check if there is any significant change in any feature distribution for the new and training datasets. \n",
    "\n",
    "**Save the results in a dictionary, and don't forget to exclude the target variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdf1ae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f479320b89643340",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ks_test_dict = {}\n",
    "#...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "ks_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97d294",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-65521b9fd493215c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ks_test_dict, dict)\n",
    "assert _hash(sorted(ks_test_dict.keys())) == '5ca69ca620', \"Have you excluded the target variable?\"\n",
    "assert math.isclose(sum(ks_test_dict.values()), 11.41, abs_tol=.01), \"Are you saving the p-value? Is it being calculated correctly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de57462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a8e06e7b86c52f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for k,v in ks_test_dict.items():\n",
    "    if v < 0.005:\n",
    "        print(\"Feature {} has changed significantly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae7d22b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c27e3ccb061f166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can safely say that we do not have a case of data drift in our hands. At least with the very basic tests that we've done. Even though if nothing has changed in the data distribution, we still have more data and we should take advantage of it! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1d356",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6116c5fc9874a98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "Combine the two datasets into one. Add a new column called `is_new` that is going to have all `False` values for the old data and all `True` values for the new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5dd4c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-905f1ad95e11cc3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# df_combined = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4928a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-59f405baf8725c0d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_combined.shape == (32561, 16), 'Combined dataframe shape is wrong.'\n",
    "assert 'is_new' in df_combined.columns, 'Did you add is_new column?'\n",
    "assert sum(df_combined['is_new']) == 14561, 'is_new column has a wrong number of True values'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0e735",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4979ebd01837370a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In total we have now 32561 observations. This dataset is still small enough that we do not have to do any data selection to retrain our model, but the same might not be true for future iterations. ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8dc832",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac2bb3e0f273242b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Split the created dataset on train and test parts in the following way:\n",
    "\n",
    "- Make sure to change the target so that it has a binary value - True or False - instead of the original values. In particular:\n",
    "    - False: client has as a salary of less than 50K\n",
    "    - True: client has as a salary higher or equal to 50K\n",
    "- Firstly create train and test set. Call them `df_train` and `df_test`. We'll need them in the future exercises.\n",
    "- Then, split train and test into `X_train`, `X_test`, `y_train` and `y_test`.\n",
    "    - Test sets shape should be 25% of df_combined shape\n",
    "    - Make sure to have 25% of new values in the test size.\n",
    "    - Use random state 42 while splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bc1d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4598367d0a6061d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b9a85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd33090db78fc4ca",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_train.shape == (24420, 16), 'df_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert df_train[target].dtype == 'bool', \"Have you changed the target variable to binary?\"\n",
    "assert df_test.shape == (8141, 16), 'df_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert df_test[target].dtype == 'bool', \"Have you changed the target variable to binary?\"\n",
    "assert X_train.shape == (24420, 15), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert X_test.shape == (8141, 15), 'X_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_train.shape == (24420,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_test.shape == (8141,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert sum(X_train['is_new']) == 10920, 'is_new column in Training set has a wrong number of True values. Make sure to have 25% of new values'\n",
    "assert sum(X_test['is_new']) == 3641, 'is_new column in Test set has a wrong number of True values. Make sure to have 25% of new values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[target].dtype == 'bool'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed936045",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-950b3692c2accef4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4\n",
    "Now we need to retrain the model.\n",
    "If we simply load the pipeline you created from BLU14 and retrain it, it's going to ignore our new feature.\n",
    "So let's create the same pipeline as in the previous BLU Exercise notebook:\n",
    "\n",
    "    Build a baseline model for this problem (don't worry about performance for now) and serialize it. Use the following features:\n",
    "\n",
    "        1) age \n",
    "        2) workclass - type of work performed by client (eg. `Private`)\n",
    "        4) education - level of education of client (eg. `Bachelors`)\n",
    "        6) marital-status - client's marital status (eg `Widowed`)\n",
    "        9) race - client's race\n",
    "        10) sex - \"male\"/\"female\"\n",
    "        11) capital-gain - total capital gain in previous year\n",
    "        12) capital-loss - total capital loss in previous year\n",
    "        13) hours-per-week - number of hours the client works per week\n",
    "\n",
    "    Note: If you use models or functions that have a random component, ensure that you pass a random state so that there are no surprises when you submit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c743af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5de474441c8f923f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a temporary directory where your serialized files will be saved. Make sure you use this as \n",
    "# the target folder when you serialize your files\n",
    "TMP_DIR = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5b0dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7530d8bc1189fb35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#numerical_features = ...\n",
    "#categorical_features = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(max_depth=3, min_samples_leaf=.03, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f674067",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8d3bed017ca3c9fd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pipeline, Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca02ba4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-854a8d6c5e7e01db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c837518",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdf215a7d96e14f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 5\n",
    "Now let's test how the model performs with the fresh new data! Here's your TODO list:\n",
    "\n",
    "- Make model binary predictions and save them to an array called `preds`.\n",
    "- Make model probability predictions and save them to an array called `preds_proba`. **Keep only True class probabilities** (by default probability prediction returns you both False and True classes probabilities)\n",
    "- Create a variable called precision with the model precision score.\n",
    "- Create a variable called recall with the model recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0c878",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2642bdb8e329b807",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f07fcb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b594688d047591a2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(recall, 0.86, abs_tol=.01), \"Your recall value is too far off. Is your pipeline correctly set?\"\n",
    "assert len(preds) == 8141, 'Are you sure you made predictions for test set only?'\n",
    "assert len(preds_proba) == 8141, 'Are you sure you made predictions for test set only?'\n",
    "assert not isinstance(preds_proba[0], np.ndarray), 'Are you sure you kept only the True class predictions?'\n",
    "assert round(sum(preds_proba)) == 3609\n",
    "assert math.isclose(precision, 0.47, abs_tol=.01), \"Your precision value is too far off. Is your pipeline correctly set?\"\n",
    "assert math.isclose(recall, 0.86, abs_tol=.01), \"Your recall value is too far off. Is your pipeline correctly set?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73603ec3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4fec662e1b35676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6\n",
    "Let's now try to calculate the optimal threshold. By threshold I mean the minimal probability of a prediction that we're going to call \"True\".\n",
    "\n",
    "By default, any prediction with probability > 0.5 is called True, but we might find a better value.\n",
    "\n",
    "The metric is the same: our success rate (precision) needs to be at least 50%, and the recall should be as big as possible.\n",
    "\n",
    "Save the result to a variable called threshold. Round the result to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce566acc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8daf046ccb24741e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# threshold = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e130e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1169c2176dcd94b3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(threshold, 2) == threshold, 'Did you round the value?'\n",
    "ans_threshold = hashlib.sha256(bytes(str(threshold), encoding='utf8')).hexdigest()\n",
    "assert ans_threshold == '37f253d59e6203142bd9b0b9a7ac8044b7217baca69cfc9846e3748a3f804cc0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e58fc9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdd7454797b55ce7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 7:\n",
    "Now create a list of predictions. \n",
    "\n",
    "- All the values from the **preds_proba** list that have a value > threshold should be True. The rest should be False. Save the result to a variable called **best_preds**\n",
    "- Calculate the precision and recall and save them to variables **precision** and **recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe7b39",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-183402c4ff14f3a2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# best_preds = ...\n",
    "# precision = ...\n",
    "# recall = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe129c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(precision, 0.4963, decimal=2)\n",
    "np.testing.assert_almost_equal(recall, 0.7790, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548b1a4",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Now let's find out whether removing rare values is going to help. \n",
    "\n",
    "**Filter *df_train* (the one you created in the Exercise 3) the following way:** \n",
    "\n",
    "- Remove rows with **education** that appear <= 50 times\n",
    "- Remove rows with **marital-status** that appear <= 30 times\n",
    "\n",
    "**Note: it's better to keep the original dataframe not touched. Create a copy of the original dataframe and save the results to a variable **train_filtered**\n",
    "\n",
    "> We have to filter the values after we split the dataset into training and test, because by filtering the test set we also affect the score. If we filtered everything besides the examples that are the easiest to predict, we'd have a super nice score, but in production we're going to expect both the filtered values and unfiltered ones. \n",
    "\n",
    "> We shouldn't worry about the fact, that some values in the test set will not be present in the training set, because the pipeline is simply going to ignore them.\n",
    "\n",
    "> (you might use the logic from the original model's notebook, but I suggest trying to implement it by yourself, it's a good exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3ba6a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-464a40e1e6037a35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train_filtered = df_train.copy()\n",
    "# train_filtered = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c3fdc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1a2d374b946aa3e3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_filtered.shape == (24365, 16), 'Make sure to filter rare values. Make sure to filter only train set.'\n",
    "assert 'Preschool' not in train_filtered['education'], 'Did you filter education?'\n",
    "assert 'Married-AF-spouse' not in train_filtered['marital-status'], 'Did you filter marital-statu?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e8188",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74cb193c45b9470c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 9\n",
    "\n",
    "The workclass has several values that represent the same information. It might be beneficial to merge them.\n",
    "\n",
    "- Merge the \"?\", \"Without-pay\" and \"Never-worked\" into a single \"No Salary\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a853b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c9b56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b57ecbc07311aa67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "#train_filtered['workclass'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c120c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ad7f12498232f88c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(train_filtered['workclass']) == 24365\n",
    "assert len(train_filtered['workclass'][train_filtered['workclass'] == \"No Salary\"]) == 1421"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2933e94",
   "metadata": {},
   "source": [
    "## Exercise 10\n",
    "\n",
    "**Let's split *train_filtered* into *X* and *Y* parts and do the same thing once again:**\n",
    "\n",
    "- Fit the model on the training set (this time filtered one)\n",
    "\n",
    "- Predict probabilities for the test set (untouched one).\n",
    "\n",
    "- Select the best threshold for the specified requirements (precision >= 0.5, max possible recall).\n",
    "\n",
    "- Round up the threshold up to 2 decimal points.\n",
    "\n",
    "- Transform probabilities to binary answers: probability above the threshold = True, False otherwise.\n",
    "\n",
    "- Calculate the precision and recall scores for these predictions. \n",
    "\n",
    "I believe you need no exact instructions, as you did exactly same things in Exercises 3, 4 and 5. ;)\n",
    "\n",
    "Save the score results to variables called **filtered_precision** and **filtered_recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c9d89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6dcd4961cd62a260",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3a0d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-db39a36ffa243bdc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(filtered_precision, 0.5046, decimal=2)\n",
    "np.testing.assert_almost_equal(filtered_recall, 0.75581, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e93857",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6629cdeb140a69f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fc799",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f83dae43b3828639",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So, we got the model, and our precision is now above the needed treshold! It's usually a good idea to **retrain the model on the whole dataset**, so now I want you to:\n",
    "- Apply the filters that you just created in the Exercise 8 to **df_combined**\n",
    "- Apply the transformation to the workclass to **df_combined**\n",
    "- Train the same model on the whole dataset\n",
    "- Export the model, train columns and data types to **/tmp/<file_name>**, where files are called **new_pipeline.pickle**, **new_dtypes.pickle** and **new_columns.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbb094",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb28e12d8a8a4577",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97683298",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cf52c8c09d0bd55c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(TMP_DIR, 'new_columns.json')) as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "with open(os.path.join(TMP_DIR, 'new_pipeline.pickle'), 'rb') as fh:\n",
    "    pipeline = joblib.load(fh)\n",
    "\n",
    "with open(os.path.join(TMP_DIR, 'new_dtypes.pickle'), 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "assert isinstance(columns, list), 'columns need to be a list of training features'\n",
    "assert 'salary' not in columns, 'there should be only training features in columns. You got target there.'\n",
    "assert 'is_new' in columns, \"your columns don't contain is_new feature. Are you you updated the columns file?\"\n",
    "assert isinstance(pipeline, Pipeline), 'new_pipeline.pickle does not seem it be an instance of Pipeline class.'\n",
    "assert isinstance(dtypes, pd.core.series.Series)\n",
    "assert all([column in dtypes.index for column in columns]), 'some columns from new_columns file are not in the new_dtypes file'\n",
    "assert all([dtype in columns for dtype in dtypes.index]), 'some dtypes from new_dtypes file are not in the new_columns file'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7975d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23b7f5e0911f976b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 12 (ungraded)\n",
    "And now it's time to change the server! I know you missed this part :)\n",
    "\n",
    "Before we do it, I want to remind you that in this exercise we didn't cover the ethics topic. Our model is trained on sensible features like race and sex. In a real situation you'd need to make sure that your model is not discriminating anyone.\n",
    "\n",
    "Now, go and create a copy of the protected_server.py file. Call it new_server.py\n",
    "\n",
    "In that file:\n",
    "\n",
    "- Change the check_valid_column function to have the new added columns You can also automate it by reading the columns file, it's even better!\n",
    "\n",
    "- Change the check_categorical_values function: Make sure the values there still make sense!\n",
    "\n",
    "- We also add one more categorical feature to the dataframe (is_new). Go and add possible values to the check.\n",
    "\n",
    "As soon as it's done, go ahead and start the server.\n",
    "\n",
    "Play with the predictions. Make sure that the server checks the is_new feature values. Try to send requests without is_new or with a different value (not True or False).\n",
    "\n",
    "After you're done, change the value of done to True to pass the exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01373f58",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3ce6e306628b0403",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#done = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85908a85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95fb4a083fa2c67b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert done == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f009307",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fa76646e473e3657",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There's much more we can do with this dataset to train a better model, and more importantly, a model that doesn't descriminate. So if you're willing, go crazy! Make the best model you can! It's great preparation for the hackathon! ;) See you there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
